{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tile-based classification using Sentinel-2 L1C  and EuroSAT data-Inference.ipynb",
      "provenance": [],
      "mount_file_id": "1ybbQTHScMz7y2Gur32DgQOvoFSKQRtWc",
      "authorship_tag": "ABX9TyNWQ/dgF2C/bRyP2psGA88O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoronto/ml-unstructured-data-projects/blob/master/Tile_based_classification_using_Sentinel_2_L1C_and_EuroSAT_data_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igPDT5gC32Ga"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "This workflow explores the process of infering land use / classification from a pre-trained model based on the benchmark EuroSAT dataset. This note book contains notes I've taken as I work through the example workflows presented in the AI for Earth monitoring MOOC on Futurelearn.\n",
        "\n",
        "This is the second of a two part practice module, the first part of this two part series explores the process of training a convolutional neural network based on EuroSAT benchmark data for land use/land cover classification while the second part explores the workflow for utilising the learned capabilities of our pre-trained model to infer land use / land cover classification on a Sentinel-2 level-1C tile image.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO04EX-h6mJI"
      },
      "source": [
        "## **Data**\n",
        "\n",
        "The inference process utilizes the following data:\n",
        "\n",
        "* a `Sentinel-2 level-1C file`, which is available in the following folder: ./S2_Tile_based_classification/01_input_data/S2_tile_4_inference.\n",
        "The scene shows a coasteal part over Italy on March 31, 20121. The scene is used as input data for the pretrained model in order to infer land use/land cover classes.\n",
        "* a `pretrained  model`, a `convolutional neural network` which has been trained based on EuroSAT  data, as a benchmark dataset for land use / land cover classifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nruaCeA-6p0V"
      },
      "source": [
        "## **Additional Resources**\n",
        "\n",
        "* 3B - Tile-based classification with EuroSAT data - Training\n",
        "* EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification\n",
        "* EuroSAT data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlGo-MO860kU"
      },
      "source": [
        "## **Notebook Outline**\n",
        "\n",
        "* 1 - Load a Sentinel-2 Level 1-C tile\n",
        "* 2 - Resample all bands of a Seninel-2 Level 1-C tile to 10m spatial resolution\n",
        "* 3 - Reorder the bands according to the order of the pretrained model\n",
        "* 4 - Load the pretrained sequential convolutional neural network based on EuroSAT data\n",
        "* 5 - Divide the Sentinel-2 L1C tile into  64x64 windows\n",
        "* 6 - Infer land use classes\n",
        "* 7 - Visualize the final classified image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9YkbgoSV2e"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiqlwo6HDQZ9"
      },
      "source": [
        "## Begin S3FS import snippet ##\n",
        "import os, sys\n",
        "s3_home = os.getcwd()\n",
        "try: sys.path.remove(s3_home) # Remove the S3 root from the path\n",
        "except Exception: pass\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# os.chdir('/home/jovyan') # Temporarily move to another directory\n",
        "\n",
        "# Begin imports #\n",
        "import tensorflow as tf\n",
        "from osgeo import gdal_array, osr, gdal\n",
        "import glob\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# end imports #\n",
        "\n",
        "os.chdir(current_dir) # go back to your previous directory\n",
        "\n",
        "sys.path.append(s3_home) # restore the s3 root in the path\n",
        "\n",
        "## end s3fs import snippet ##"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OB5oBwltcVA"
      },
      "source": [
        "## Begin S3FS Import Snippet ##\n",
        "import os, sys\n",
        "s3_home = os.getcwd()\n",
        "try: sys.path.remove(s3_home) # Remove the S3 from the $path\n",
        "except Exception: pass\n",
        "\n",
        "# current_dir = os.getcwd()\n",
        "\n",
        "# os.chdir('/home/jovyan') # Temporarily move to another directory\n",
        "\n",
        "# Begin imports #\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from osgeo import gdal_array\n",
        "from matplotlib import pyplot as pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "# end imports #\n",
        "\n",
        "# os.chdir(current_dir) # go back to your previous dir\n",
        "\n",
        "# sys.path.append(s3_home) # restore the s3 root in the $path\n",
        "\n",
        "## end s3fs import snippet ##\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-DF0lwEWyWk"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3mvsK6CKOO-"
      },
      "source": [
        "from_folder_to_stack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwNtHfldXIaf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "'''\n",
        "function name:\n",
        "  from_folder_to_stack\n",
        "description:\n",
        "  This function transforms the .SAFE file into three different arrays (10m, 20m and 60m).\n",
        "Input:\n",
        "  safe_path: the path of the .SAFE file;\n",
        "  data_bands_20m: if True, the fumnction computes stack using Sentinel2 band with 20m of pixel resolution (default=True);\n",
        "  data_bands_60m: if True, the function computes stack using Sentinel2 band with 60m of pixel resolution (default=True);\n",
        "Output:\n",
        "  stack_10m: stack with the following S2L1C bands (B02, B03, B04, B08)\n",
        "  stack_20m: stack with the following S2L1C bands (B05, B06, B07, B11, B12, B8A)\n",
        "  stack_60m: stack with the following S2L1C bands (B01, mB09, B10)\n",
        "'''\n",
        "def from_folder_to_stack(\n",
        "    safe_path,\n",
        "    data_bands_20m=True,\n",
        "    data_bands_60m=True,\n",
        "    ):\n",
        "\n",
        "  level_folder_name_list = glob.glob(safe_path + 'GRANULE/*')\n",
        "  level_folder_name = level_folder_name_list[0]\n",
        "\n",
        "  if level_folder_name.find(\"L2A\") < 0:\n",
        "    safe_path = [level_folder_name + '/IMG_DATA/']\n",
        "  else:\n",
        "    safe_path_10m = level_folder_name + '/IMG_DATA/R10m/'\n",
        "    safe_path = [safe_path_10m]\n",
        "\n",
        "  text_files = []\n",
        "\n",
        "  for i in range(0, len(safe_path)):\n",
        "      print(\"[AI4EO_MOOC]_log: Loading .jp2 images in %s\" % (safe_path[i]))\n",
        "      text_files_tmp = [f for f in os.listdir(safe_path[i]) if f.endswith('.jp2')]\n",
        "      text_files.append(text_files_tmp)\n",
        "\n",
        "  lst_stack_60m=[]\n",
        "  lst_code_60m=[]\n",
        "  lst_stack_20m=[]\n",
        "  lst_code_20m=[]\n",
        "  lst_stack_10m=[]\n",
        "  lst_code_10m=[]\n",
        "  for i in range(0, len(safe_path)):\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Reading .jp2 files in %s\" % (safe_path[i]))\n",
        "    for name in range(0, len(text_files[i])):\n",
        "      text_files_tmp = text_files[i]\n",
        "      if data_bands_60m == True:\n",
        "        cond_60m = ( (text_files_tmp[name].find(\"B01\") > 0) or (text_files_tmp[name].find(\"B09\") > 0)\n",
        "                    or (text_files_tmp[name].find(\"B10\") > 0))\n",
        "        if cond_60m:\n",
        "            print(\"[AI4EO_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "            lst_stack_60m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "            lst_code_60m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "      if data_bands_20m == True:\n",
        "          cond_20m = (text_files_tmp[name].find(\"B05\") > 0) or (text_files_tmp[name].find(\"B06\") > 0) or (\n",
        "                      text_files_tmp[name].find(\"B07\") > 0) or (text_files_tmp[name].find(\"B11\") > 0) or (\n",
        "                                  text_files_tmp[name].find(\"B12\") > 0) or (text_files_tmp[name].find(\"B8A\") > 0)\n",
        "          cond_60m_L2 = (text_files_tmp[name].find(\"B05_60m\") < 0) and (text_files_tmp[name].find(\"B06_60m\") < 0) and (\n",
        "                      text_files_tmp[name].find(\"B07_60m\") < 0) and (text_files_tmp[name].find(\"B11_60m\") < 0) and (\n",
        "                                  text_files_tmp[name].find(\"B12_60m\") < 0) and (text_files_tmp[name].find(\"B8A_60m\") < 0)\n",
        "          cond_20m_tot = cond_20m and cond_60m_L2\n",
        "          if cond_20m_tot:\n",
        "              print(\"[AI4E_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "              lst_stack_20m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "              lst_code_20m.append(text_files_tmp[name][24:26])\n",
        "      else:\n",
        "        stack_20m = 0\n",
        "\n",
        "      cond_10m = (text_files_tmp[name].find(\"B02\") > 0) or (text_files_tmp[name].find(\"B03\") > 0) or (\n",
        "                  text_files_tmp[name].find(\"B04\") > 0) or (text_files_tmp[name].find(\"B08\") > 0)\n",
        "      cond_20m_L2 = (text_files_tmp[name].find(\"B02_20m\") < 0) and (text_files_tmp[name].find(\"B03_20m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_20m\") < 0) and (text_files_tmp[name].find(\"B08_20m\") < 0)\n",
        "      cond_60m_L2 = (text_files_tmp[name].find(\"B02_60m\") < 0) and (text_files_tmp[name].find(\"B03_60m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_60m\") < 0) and (text_files_tmp[name].find(\"B08_60m\") < 0)\n",
        "      cond_10m_tot = cond_10m and cond_20m_L2 and cond_60m_L2\n",
        "\n",
        "      if cond_10m_tot:\n",
        "          print(\"[AI4E)_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "          lst_stack_10m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "          lst_code_10m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "\n",
        "  stack_10m=np.asarray(lst_stack_10m)\n",
        "  sorted_list_10m = ['02', '03', '04', '08']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 10m...')\n",
        "  stack_10m_final_sorted = stack_sort(stack_10m, lst_code_10m, sorted_list_10m)\n",
        "\n",
        "  stack_20m=np.asarray(lst_stack_20m)\n",
        "  sorted_list_20m = ['05', '06', '07', '11', '12', '8A']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 20m...')\n",
        "  stack_20m_final_sorted = stack_sort(stack_20m, lst_code_20m, sorted_list_20m)\n",
        "              \n",
        "  stack_60m=np.asarray(lst_stack_60m)\n",
        "  sorted_list_60m = ['01', '09', '10']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 60m...')\n",
        "  stack_60m_final_sorted = stack_sort(stack_60m, lst_code_60m, sorted_list_60m)\n",
        "\n",
        "  return stack_10m_final_sorted, stack_20m_final_sorted, stack_60m_final_sorted"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwSv2ExkGK9e"
      },
      "source": [
        "stack_sort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW6E0LvU_wB0"
      },
      "source": [
        "def stack_sort(stack_in, lst_code, sorted_list):\n",
        "  b, r, c = stack_in.shape\n",
        "  stack_sorted = np.zeros((r,c,b), dtype=np.unit16)\n",
        "\n",
        "  len_list_bands = len(lst_code)\n",
        "\n",
        "  c = np.zeros((len_list_bands), dtype=np.unit8)\n",
        "  count = 0\n",
        "  count_sort = 0\n",
        "  while count_sort != len_list_bands:\n",
        "    if lst_code[count] == sorted_list[count_sort]:\n",
        "      c[count_sort] = count\n",
        "      count_sort = count_sort + 1\n",
        "      count = 0\n",
        "    else:\n",
        "      count = count + 1\n",
        "    print('[AI4EO_MOOC]_log: sorted list:', sorted_list)\n",
        "    print('[AI4EO_MOOC]_log: bands:', c)\n",
        "    for i in range(0, len_list_bands):\n",
        "        stack_sorted[:,:,i]=stack_in[c[i],:,:]\n",
        "    \n",
        "    return stack_sorted"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYkZZV_IrQs"
      },
      "source": [
        "resample_3d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS-jKoKI8uK"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  resample_3d\n",
        "description:\n",
        "  wrapper of ndimage zoom. Bilinear interpolation for resampling array\n",
        "input:\n",
        "  stack: array to be resampled;\n",
        "  row10m: the expected row;\n",
        "  col10m: the expected col;\n",
        "  rate: the rate of the transformation;\n",
        "output:\n",
        "  stack_10m: resampled array\n",
        "'''\n",
        "def resample_3d(\n",
        "        stack,\n",
        "        row10m,\n",
        "        col10m,\n",
        "        rate):\n",
        "    row, col, bands = stack.shape\n",
        "    print(\"[AI4EO_MOOC]_log: Array shape (%d,%d,%d)\" % (row, col, bands))\n",
        "\n",
        "    stack_10m = np.zeros((row10m, col10m, bands),dtype=np.uint16)\n",
        "    print(\"[AI4EO_MOOC]_log: Resize array bands from (%d,%d,%d) to (%d,%d,%d)\" % (\n",
        "        row, col, bands, row10m, col10m, bands))\n",
        "    \n",
        "    for i in range(0, bands):\n",
        "      stack_10m[:, :, i] = ndimage.zoom(stack[:, :,i], rate)\n",
        "\n",
        "    del (stack)\n",
        "\n",
        "    return stack_10m"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0Kp7sWIwPk"
      },
      "source": [
        "sentinel2_format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3mAuYCJAO-"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  sentinel2_format\n",
        "description:\n",
        "  This function transforms the multistack into sentinel2 format arrays with bands in the right positions for our AI model.\n",
        "input:\n",
        "  total_stack: array that is the concatenation of stack10, stack_20mTo10m and stack_60mTo10m.\n",
        "output:\n",
        "  sentinel2: sentinel2 format array\n",
        "'''\n",
        "def sentinel2_format(\n",
        "        total_stack):\n",
        "  \n",
        "    row_tot, col_tot, bands_tot = total_stack.shape\n",
        "    sentinel2 = np.zeros((row_tot, col_tot, bands_tot),dtype=np.unit16)\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Creating a total stack with following list of bands:\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 1 - Coastal aerosol\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 2 - Blue\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 3 - Green\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 4 - Red\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 5 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 6 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 7 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8 - NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8A - Narrow NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 9 - Water vapour\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 10 - SWIR - Cirrus\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 11 - SWIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 12 - SWIR\")\n",
        "\n",
        "    sentinel2[:, :, 0] = total_stack[:, :, 10]\n",
        "    sentinel2[:, :, 1] = total_stack[:, :, 0]\n",
        "    sentinel2[:, :, 2] = total_stack[:, :, 1]\n",
        "    sentinel2[:, :, 3] = total_stack[:, :, 2]\n",
        "    sentinel2[:, :, 4] = total_stack[:, :, 4]\n",
        "    sentinel2[:, :, 5] = total_stack[:, :, 5]\n",
        "    sentinel2[:, :, 6] = total_stack[:, :, 6]\n",
        "    sentinel2[:, :, 7] = total_stack[:, :, 3]\n",
        "    sentinel2[:, :, 8] = total_stack[:, :, 9]\n",
        "    sentinel2[:, :, 9] = total_stack[:, :, 11]\n",
        "    sentinel2[:, :, 10] = total_stack[:, :, 12]\n",
        "    sentinel2[:, :, 11] = total_stack[:, :, 7]\n",
        "    sentinel2[:, :, 12] = total_stack[:, :, 8]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rf5SvGdpOko"
      },
      "source": [
        "\n",
        "'''\n",
        "function name:\n",
        "  sentinel2_format\n",
        "description:\n",
        "  This function transforms the multistack into sentinel2 format arrays with bands in the right positions for our AI model.\n",
        "input:\n",
        "  total_stack: array that is the concatenation of stack10, stack_20mTo10m and stack_60mTo10m.\n",
        "output:\n",
        "  sentinel2: sentinel2 format array\n",
        "'''\n",
        "def sentinel2_format(\n",
        "        total_stack):\n",
        "  \n",
        "    row_tot, col_tot, bands_tot = total_stack.shape\n",
        "    sentinel2 = np.zeros((row_tot, col_tot, bands_tot),dtype=np.unit16)\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Creating a total stack with following list of bands:\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 1 - Coastal aerosol\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 2 - Blue\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 3 - Green\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 4 - Red\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 5 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 6 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 7 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8 - NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8A - Narrow NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 9 - Water vapour\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 10 - SWIR - Cirrus\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 11 - SWIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 12 - SWIR\")\n",
        "\n",
        "    sentinel2[:, :, 0] = total_stack[:, :, 10]\n",
        "    sentinel2[:, :, 1] = total_stack[:, :, 0]\n",
        "    sentinel2[:, :, 2] = total_stack[:, :, 1]\n",
        "    sentinel2[:, :, 3] = total_stack[:, :, 2]\n",
        "    sentinel2[:, :, 4] = total_stack[:, :, 4]\n",
        "    sentinel2[:, :, 5] = total_stack[:, :, 5]\n",
        "    sentinel2[:, :, 6] = total_stack[:, :, 6]\n",
        "    sentinel2[:, :, 7] = total_stack[:, :, 3]\n",
        "    sentinel2[:, :, 8] = total_stack[:, :, 9]\n",
        "    sentinel2[:, :, 9] = total_stack[:, :, 11]\n",
        "    sentinel2[:, :, 10] = total_stack[:, :, 12]\n",
        "    sentinel2[:, :, 11] = total_stack[:, :, 7]\n",
        "    sentinel2[:, :, 12] = total_stack[:, :, 8]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_P1HyB9I3Y8"
      },
      "source": [
        "sliding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfdgOtpfI-TY"
      },
      "source": [
        "'''\n",
        "Function_name:\n",
        "  sliding\n",
        "description:\n",
        "input:\n",
        "  shape: the target shape\n",
        "  window_size: the shape of the window\n",
        "  step-size:\n",
        "  fixed\n",
        "output:\n",
        "  windows:\n",
        "'''\n",
        "\n",
        "def sliding(shape, window_size, step_size=None, fixed=True):\n",
        "    h, w = shape\n",
        "    if step_size:\n",
        "        h_step = step_size\n",
        "        w_step = step_size\n",
        "    else:\n",
        "        h_step = window_size\n",
        "        w_step = window_size\n",
        "\n",
        "    h_wind = window_size\n",
        "    w_wind = window_size\n",
        "    windows = []\n",
        "    for y in range(0, h, h_step):\n",
        "        for x in range(0, w, w_step):\n",
        "            h_min = min(h_wind, h - y)\n",
        "            w_min = min(w_wind, w - x)\n",
        "            if fixed:\n",
        "              if h_min < h_wind or w_min < w_wind:\n",
        "                  continue\n",
        "            window = (x, y, w_min, h_min)\n",
        "            windows.append(window)\n",
        "\n",
        "    return windows"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4upB8g262XH"
      },
      "source": [
        "# **1. Load a Sentinel-2 Level-1C tile**\n",
        "\n",
        "In the first step, we lod the input data for the inference process. The input data is a Sentinel2 Level-1C tile which shall be classified with the help of the pre-trained model.\n",
        "\n",
        "Let us define the Python dictionary which holds information about where the Sentinel-2 Level-1C data is stored. Next we'll define `main_path`, `sentinel2_safe_name` and `sentinel2_safe_path`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i8-7-jDSd1p"
      },
      "source": [
        "data_input = {}\n",
        "data_input['main_path'] ='/content/drive/MyDrive/Land Classification/S2_Tile_based_classification/'\n",
        "\n",
        "data_input['sentinel2_safe_name'] = 'S2A_MSIL1C_20210331T100021_N0300_R122_T33TTG_20210331T113321.SAFE/'\n",
        "data_input['sentinel2_safe_path'] = data_input['main_path']+'01_Input_data/S2_tile_4_inference/' + data_input['sentinel2_safe_name']"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvbReGKCpFXm"
      },
      "source": [
        "The next step makes use of the `function from_folder_to_stack()`. The functions transforms the Sentinel-2 Level-1C file which is disseminated in the `.SAFE` format into three different arrays, each combining the bands with the same spatial resolution. Sentinel-2 samples 13 spectral bands, which have three different resolutions:`10m, 20m and 60m`.\n",
        "\n",
        "The result of the function are three stacked arrays:\n",
        "\n",
        "* `stack_10m`: stack combining bands with 10m spatial resolution `(B02, B03, B04, B08)\n",
        "* `stack_20m`: stack combining bands with 20m spatial resolution `(B05, B06, B07, B11, B12, B8A)\n",
        "* `stack_60m`: stack combining bands with 60m spatial resolution `(B01, B09, B10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "Hmcdhnv7ptht",
        "outputId": "49397824-8c8d-442c-ffd3-b5ee8fecbbac"
      },
      "source": [
        "import numpy as np\n",
        "safe_path = data_input['sentinel2_safe_path']\n",
        "stack_10m, stack_20m, stack_60m = from_folder_to_stack(safe_path)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Loading .jp2 images in /content/drive/MyDrive/Land Classification/S2_Tile_based_classification/01_Input_data/S2_tile_4_inference/S2A_MSIL1C_20210331T100021_N0300_R122_T33TTG_20210331T113321.SAFE/GRANULE/L1C_T33TTG_A030149_20210331T100404/IMG_DATA/\n",
            "[AI4EO_MOOC]_log: Reading .jp2 files in /content/drive/MyDrive/Land Classification/S2_Tile_based_classification/01_Input_data/S2_tile_4_inference/S2A_MSIL1C_20210331T100021_N0300_R122_T33TTG_20210331T113321.SAFE/GRANULE/L1C_T33TTG_A030149_20210331T100404/IMG_DATA/\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B10.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B09.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B01.jp2\n",
            "[AI4E_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B05.jp2\n",
            "[AI4E_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B07.jp2\n",
            "[AI4E_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B06.jp2\n",
            "[AI4E_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B11.jp2\n",
            "[AI4E_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B8A.jp2\n",
            "[AI4E_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B12.jp2\n",
            "[AI4E)_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B03.jp2\n",
            "[AI4E)_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B04.jp2\n",
            "[AI4E)_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B08.jp2\n",
            "[AI4E)_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B02.jp2\n",
            "[AI4EO_MOOC]_log: Sorting stack 10m...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-ac586fb8c50b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msafe_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentinel2_safe_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstack_10m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_20m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_60m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_folder_to_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-63b678e65515>\u001b[0m in \u001b[0;36mfrom_folder_to_stack\u001b[0;34m(safe_path, data_bands_20m, data_bands_60m)\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0msorted_list_10m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'02'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'03'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'04'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'08'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[AI4EO_MOOC]_log: Sorting stack 10m...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0mstack_10m_final_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_10m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst_code_10m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_list_10m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mstack_20m\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_stack_20m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-99f7efa1a179>\u001b[0m in \u001b[0;36mstack_sort\u001b[0;34m(stack_in, lst_code, sorted_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack_sort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mstack_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mlen_list_bands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0;32m--> 215\u001b[0;31m                                      \"{!r}\".format(__name__, attr))\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'unit16'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ilFKkIVQwXf"
      },
      "source": [
        "On inspecting the dimensions of the three stacked arrays, we 'll notice that the stack combining bands with 10m resolution consists of 4 bands. The one combining bands with 20m resolution consists of 6 bands and the one combining bands with 60m resolution consists of 3 bands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTBtVvysQyOI"
      },
      "source": [
        "print(stack_10m.shape)\n",
        "print(stack_20m.shape)\n",
        "print(stack_60m.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLm-Rv0i8rsX"
      },
      "source": [
        "#**2. Resample all bands of a Seninel-2 Level 1-C tile to 10m spatial resolution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiHPX_jipptE"
      },
      "source": [
        "In the next step we resample the arrays containing bands with 20m and 60m resolution. You can use the function `resample_3d()` to achive this. The function takes the following keyword arguments:\n",
        "\n",
        "* `stack`: array to be resampled to 10m\n",
        "* `row10m`: number of rows of the 10m resolution array\n",
        "* `col10m`: number of columns of the 10m resolution array\n",
        "* `rate`: to which rate the input stack shall be resampled\n",
        "\n",
        "We have to apply the function to both array stacks, `stack_20m` and `stack_60m`. This results in all three stacks having the same spatial resolution of 10m."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VIEJ2tMu_KQ"
      },
      "source": [
        "n_row, n_col b10 = stack_10m.shape\n",
        "\n",
        "print('[AI4EO_MOOC]_log: Resampling stack with 20 m pixel size...')\n",
        "stack_20mTo10m = resample_3d(stack = stack_20m,\n",
        "                             row10m = n_row,\n",
        "                             col10m = n_col,\n",
        "                             rate= 2)\n",
        "\n",
        "print('[AI4EO_MOOC]_log: Resampling stack with 60 m pixel size...')\n",
        "stack_60mTo10m = resample_3d(stack = stack_60m,\n",
        "                             row10m = n_row,\n",
        "                             col10m = n_col,\n",
        "                             rate= 6)\n",
        "\n",
        "print(stack_20mTo10m.shape)\n",
        "print(stack_60mTo10m.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGz0oluv89IP"
      },
      "source": [
        "#**3. Reorder the bands according to the order of the pretrained model**\n",
        "\n",
        "The three array stack now have the same spatial resolution. In a next step, we'll concatenate them with the numpy function `concatenate`. We want to concatenate them on the band dimensions (axis=2). The result is one array with a spatial resolution of 10m and 13 bands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMY0AAOLG9dR"
      },
      "source": [
        "print('(AI4EO_MOOC)_log: Creating multistack with 10-20-60 m pixel size')\n",
        "\n",
        "total_stack=np.concatenate((stack_10m, stack_20mTo10m, stack_60mTo10m),\n",
        "                           axis=2)\n",
        "\n",
        "total_stack.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r22YiboHswz"
      },
      "source": [
        "You cannow plot the reflectance for each band for one pixel with matplotlib's `plot()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1q-1g6iH-zK"
      },
      "source": [
        "plt.ylabel(\"Refelectance\")\n",
        "plt.xlabel(\"Band\")\n",
        "plt.plot(total_stack[200,200,:1],'-o')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YicVi6F9Hqk"
      },
      "source": [
        "#**4. Load the pretrained sequential convolutional neural network based on EuroSAT data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB5OtCYy9NUg"
      },
      "source": [
        "#**5. Divide the Sentinel-2 L1C tile into  64x64 windows**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPbLp7xL9Z8v"
      },
      "source": [
        "#**6. Infer land use classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jYod3ZD9ljF"
      },
      "source": [
        "#**7. Visualize the final classified image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeiHqIzQ9tB9"
      },
      "source": [
        ""
      ]
    }
  ]
}