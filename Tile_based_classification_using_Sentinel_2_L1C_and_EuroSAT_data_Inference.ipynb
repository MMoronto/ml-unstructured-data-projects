{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tile-based classification using Sentinel-2 L1C  and EuroSAT data-Inference.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPvPBEBVmZzFvy0tRgzdL8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoronto/ml-unstructured-data-projects/blob/master/Tile_based_classification_using_Sentinel_2_L1C_and_EuroSAT_data_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igPDT5gC32Ga"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "This workflow explores the process of infering land use / classification from a pre-trained model based on the benchmark EuroSAT dataset. This note book contains notes I've taken as I work through the example workflows presented in the AI for Earth monitoring MOOC on Futurelearn.\n",
        "\n",
        "This is the second of a two part practice module, the first part of this two part series explores the process of training a convolutional neural network based on EuroSAT benchmark data for land use/land cover classification while the second part explores the workflow for utilising the learned capabilities of our pre-trained model to infer land use / land cover classification on a Sentinel-2 level-1C tile image.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO04EX-h6mJI"
      },
      "source": [
        "## **Data**\n",
        "\n",
        "The inference process utilizes the following data:\n",
        "\n",
        "* a `Sentinel-2 level-1C file`, which is available in the following folder: ./S2_Tile_based_classification/01_input_data/S2_tile_4_inference.\n",
        "The scene shows a coasteal part over Italy on March 31, 20121. The scene is used as input data for the pretrained model in order to infer land use/land cover classes.\n",
        "* a `pretrained  model`, a `convolutional neural network` which has been trained based on EuroSAT  data, as a benchmark dataset for land use / land cover classifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nruaCeA-6p0V"
      },
      "source": [
        "## **Additional Resources**\n",
        "\n",
        "* 3B - Tile-based classification with EuroSAT data - Training\n",
        "* EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification\n",
        "* EuroSAT data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlGo-MO860kU"
      },
      "source": [
        "## **Notebook Outline**\n",
        "\n",
        "* 1 - Load a Sentinel-2 Level 1-C tile\n",
        "* 2 - Resample all bands of a Seninel-2 Level 1-C tile to 10m spatial resolution\n",
        "* 3 - Reorder the bands according to the order of the pretrained model\n",
        "* 4 - Load the pretrained sequential convolutional neural network based on EuroSAT data\n",
        "* 5 - Divide the Sentinel-2 L1C tile into  64x64 windows\n",
        "* 6 - Infer land use classes\n",
        "* 7 - Visualize the final classified image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9YkbgoSV2e"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiqlwo6HDQZ9"
      },
      "source": [
        "## Begin S3FS import snippet ##\n",
        "import os, sys\n",
        "s3_home = os.getcwd()\n",
        "try: sys.path.remove(s3_home) # Remove the S3 root from the path\n",
        "except Exception: pass\n",
        "\n",
        "# Begin imports #\n",
        "import tensorflow as tf\n",
        "from osgeo import gdal_array, osr, gdal\n",
        "import glob\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# end imports #\n",
        "\n",
        "# os.chdir(current_dir) # go back to your previous directory\n",
        "\n",
        "sys.path.append(s3_home) # restore the s3 root in the path\n",
        "\n",
        "## end s3fs import snippet ##"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-DF0lwEWyWk"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3mvsK6CKOO-"
      },
      "source": [
        "from_folder_to_stack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwNtHfldXIaf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "'''\n",
        "function name:\n",
        "  from_folder_to_stack\n",
        "description:\n",
        "  This function transforms the .SAFE file into three different arrays (10m, 20m and 60m).\n",
        "Input:\n",
        "  safe_path: the path of the .SAFE file;\n",
        "  data_bands_20m: if True, the fumnction computes stack using Sentinel2 band with 20m of pixel resolution (default=True);\n",
        "  data_bands_60m: if True, the function computes stack using Sentinel2 band with 60m of pixel resolution (default=True);\n",
        "Output:\n",
        "  stack_10m: stack with the following S2L1C bands (B02, B03, B04, B08)\n",
        "  stack_20m: stack with the following S2L1C bands (B05, B06, B07, B11, B12, B8A)\n",
        "  stack_60m: stack with the following S2L1C bands (B01, mB09, B10)\n",
        "'''\n",
        "def from_folder_to_stack(\n",
        "    safe_path,\n",
        "    data_bands_20m=True,\n",
        "    data_bands_60m=True,\n",
        "    ):\n",
        "\n",
        "  level_folder_name_list = glob.glob(safe_path + 'GRANULE/*')\n",
        "  level_folder_name = level_folder_name_list[0]\n",
        "\n",
        "  if level_folder_name.find(\"L2A\") < 0:\n",
        "    safe_path = [level_folder_name + '/IMG_DATA/']\n",
        "  else:\n",
        "    safe_path_10m = level_folder_name + '/IMG_DATA/R10m/'\n",
        "    safe_path = [safe_path_10m]\n",
        "\n",
        "  text_files = []\n",
        "\n",
        "  for i in range(0, len(safe_path)):\n",
        "      print(\"[AI4EO_MOOC]_log: Loading .jp2 images in %s\" % (safe_path[i]))\n",
        "      text_files_tmp = [f for f in os.listdir(safe_path[i]) if f.endswith('.jp2')]\n",
        "      text_files.append(text_files_tmp)\n",
        "\n",
        "  lst_stack_60m=[]\n",
        "  lst_code_60m=[]\n",
        "  lst_stack_20m=[]\n",
        "  lst_code_20m=[]\n",
        "  lst_stack_10m=[]\n",
        "  lst_code_10m=[]\n",
        "  for i in range(0, len(safe_path)):\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Reading .jp2 files in %s\" % (safe_path[i]))\n",
        "    for name in range(0, len(text_files[i])):\n",
        "      text_files_tmp = text_files[i]\n",
        "      if data_bands_60m == True:\n",
        "        cond_60m = ( (text_files_tmp[name].find(\"B01\") > 0) or (text_files_tmp[name].find(\"B09\") > 0)\n",
        "                    or (text_files_tmp[name].find(\"B10\") > 0))\n",
        "        if cond_60m:\n",
        "            print(\"[AI4EO_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "            lst_stack_60m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "            lst_code_60m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "      if data_bands_20m == True:\n",
        "          cond_20m = (text_files_tmp[name].find(\"B05\") > 0) or (text_files_tmp[name].find(\"B06\") > 0) or (\n",
        "                      text_files_tmp[name].find(\"B07\") > 0) or (text_files_tmp[name].find(\"B11\") > 0) or (\n",
        "                                  text_files_tmp[name].find(\"B12\") > 0) or (text_files_tmp[name].find(\"B8A\") > 0)\n",
        "          cond_60m_L2 = (text_files_tmp[name].find(\"B05_60m\") < 0) and (text_files_tmp[name].find(\"B06_60m\") < 0) and (\n",
        "                      text_files_tmp[name].find(\"B07_60m\") < 0) and (text_files_tmp[name].find(\"B11_60m\") < 0) and (\n",
        "                                  text_files_tmp[name].find(\"B12_60m\") < 0) and (text_files_tmp[name].find(\"B8A_60m\") < 0)\n",
        "          cond_20m_tot = cond_20m and cond_60m_L2\n",
        "          if cond_20m_tot:\n",
        "              print(\"[AI4E_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "              lst_stack_20m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "              lst_code_20m.append(text_files_tmp[name][24:26])\n",
        "      else:\n",
        "        stack_20m = 0\n",
        "\n",
        "      cond_10m = (text_files_tmp[name].find(\"B02\") > 0) or (text_files_tmp[name].find(\"B03\") > 0) or (\n",
        "                  text_files_tmp[name].find(\"B04\") > 0) or (text_files_tmp[name].find(\"B08\") > 0)\n",
        "      cond_20m_L2 = (text_files_tmp[name].find(\"B02_20m\") < 0) and (text_files_tmp[name].find(\"B03_20m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_20m\") < 0) and (text_files_tmp[name].find(\"B08_20m\") < 0)\n",
        "      cond_60m_L2 = (text_files_tmp[name].find(\"B02_60m\") < 0) and (text_files_tmp[name].find(\"B03_60m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_60m\") < 0) and (text_files_tmp[name].find(\"B08_60m\") < 0)\n",
        "      cond_10m_tot = cond_10m and cond_20m_L2 and cond_60m_L2\n",
        "\n",
        "      if cond_10m_tot:\n",
        "          print(\"[AI4E)_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "          lst_stack_10m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "          lst_code_10m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "\n",
        "  stack_10m=np.asarray(lst_stack_10m)\n",
        "  sorted_list_10m = ['02', '03', '04', '08']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 10m...')\n",
        "  stack_10m_final_sorted = stack_sort(stack_10m, lst_code_10m, sorted_list_10m)\n",
        "\n",
        "  stack_20m=np.asarray(lst_stack_20m)\n",
        "  sorted_list_20m = ['05', '06', '07', '11', '12', '8A']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 20m...')\n",
        "  stack_20m_final_sorted = stack_sort(stack_20m, lst_code_20m, sorted_list_20m)\n",
        "              \n",
        "  stack_60m=np.asarray(lst_stack_60m)\n",
        "  sorted_list_60m = ['01', '09', '10']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 60m...')\n",
        "  stack_60m_final_sorted = stack_sort(stack_60m, lst_code_60m, sorted_list_60m)\n",
        "\n",
        "  return stack_10m_final_sorted, stack_20m_final_sorted, stack_60m_final_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwSv2ExkGK9e"
      },
      "source": [
        "stack_sort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW6E0LvU_wB0"
      },
      "source": [
        "def stack_sort(stack_in, lst_code, sorted_list):\n",
        "  b, r, c = stack_in.shape\n",
        "  stack_sorted = np.zeros((r,c,b), dtype=np.unit16)\n",
        "\n",
        "  len_list_bands = len(lst_code)\n",
        "\n",
        "  c = np.zeros((len_list_bands), dtype=np.unit8)\n",
        "  count = 0\n",
        "  count_sort = 0\n",
        "  while count_sort != len_list_bands:\n",
        "    if lst_code[count] == sorted_list[count_sort]:\n",
        "      c[count_sort] = count\n",
        "      count_sort = count_sort + 1\n",
        "      count = 0\n",
        "    else:\n",
        "      count = count + 1\n",
        "    print('[AI4EO_MOOC]_log: sorted list:', sorted_list)\n",
        "    print('[AI4EO_MOOC]_log: bands:', c)\n",
        "    for i in range(0, len_list_bands):\n",
        "        stack_sorted[:,:,i]=stack_in[c[i],:,:]\n",
        "    \n",
        "    return stack_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYkZZV_IrQs"
      },
      "source": [
        "resample_3d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS-jKoKI8uK"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  resample_3d\n",
        "description:\n",
        "  wrapper of ndimage zoom. Bilinear interpolation for resampling array\n",
        "input:\n",
        "  stack: array to be resampled;\n",
        "  row10m: the expected row;\n",
        "  col10m: the expected col;\n",
        "  rate: the rate of the transformation;\n",
        "output:\n",
        "  stack_10m: resampled array\n",
        "'''\n",
        "def resample_3d(\n",
        "        stack,\n",
        "        row10m,\n",
        "        col10m,\n",
        "        rate):\n",
        "    row, col, bands = stack.shape\n",
        "    print(\"[AI4EO_MOOC]_log: Array shape (%d,%d,%d)\" % (row, col, bands))\n",
        "\n",
        "    stack_10m = np.zeros((row10m, col10m, bands),dtype=np.uint16)\n",
        "    print(\"[AI4EO_MOOC]_log: Resize array bands from (%d,%d,%d) to (%d,%d,%d)\" % (\n",
        "        row, col, bands, row10m, col10m, bands))\n",
        "    \n",
        "    for i in range(0, bands):\n",
        "      stack_10m[:, :, i] = ndimage.zoom(stack[:, :,i], rate)\n",
        "\n",
        "    del (stack)\n",
        "\n",
        "    return stack_10m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0Kp7sWIwPk"
      },
      "source": [
        "sentinel2_format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3mAuYCJAO-"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  sentinel2_format\n",
        "description:\n",
        "  This function transforms the multistack into sentinel2 format arrays with bands in the right positions for our AI model.\n",
        "input:\n",
        "  total_stack: array that is the concatenation of stack10, stack_20mTo10m and stack_60mTo10m.\n",
        "output:\n",
        "  sentinel2: sentinel2 format array\n",
        "'''\n",
        "def sentinel2_format(\n",
        "        total_stack):\n",
        "  \n",
        "    row_tot, col_tot, bands_tot = total_stack.shape\n",
        "    sentinel2 = np.zeros((row_tot, col_tot, bands_tot),dtype=np.unit16)\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Creating a total stack with following list of bands:\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 1 - Coastal aerosol\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 2 - Blue\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 3 - Green\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 4 - Red\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 5 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 6 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 7 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8 - NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8A - Narrow NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 9 - Water vapour\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 10 - SWIR - Cirrus\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 11 - SWIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 12 - SWIR\")\n",
        "\n",
        "    sentinel2[:, :, 0] = total_stack[:, :, 10]\n",
        "    sentinel2[:, :, 1] = total_stack[:, :, 0]\n",
        "    sentinel2[:, :, 2] = total_stack[:, :, 1]\n",
        "    sentinel2[:, :, 3] = total_stack[:, :, 2]\n",
        "    sentinel2[:, :, 4] = total_stack[:, :, 4]\n",
        "    sentinel2[:, :, 5] = total_stack[:, :, 5]\n",
        "    sentinel2[:, :, 6] = total_stack[:, :, 6]\n",
        "    sentinel2[:, :, 7] = total_stack[:, :, 3]\n",
        "    sentinel2[:, :, 8] = total_stack[:, :, 9]\n",
        "    sentinel2[:, :, 9] = total_stack[:, :, 11]\n",
        "    sentinel2[:, :, 10] = total_stack[:, :, 12]\n",
        "    sentinel2[:, :, 11] = total_stack[:, :, 7]\n",
        "    sentinel2[:, :, 12] = total_stack[:, :, 8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_P1HyB9I3Y8"
      },
      "source": [
        "sliding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfdgOtpfI-TY"
      },
      "source": [
        "'''\n",
        "Function_name:\n",
        "  sliding\n",
        "description:\n",
        "input:\n",
        "  shape: the target shape\n",
        "  window_size: the shape of the window\n",
        "  step-size:\n",
        "  fixed\n",
        "output:\n",
        "  windows:\n",
        "'''\n",
        "\n",
        "def sliding(shape, window_size, step_size=None, fixed=True):\n",
        "    h, w = shape\n",
        "    if step_size:\n",
        "        h_step = step_size\n",
        "        w_step = step_size\n",
        "    else:\n",
        "        h_step = window_size\n",
        "        w_step = window_size\n",
        "\n",
        "    h_wind = window_size\n",
        "    w_wind = window_size\n",
        "    windows = []\n",
        "    for y in range(0, h, h_step):\n",
        "        for x in range(0, w, w_step):\n",
        "            h_min = min(h_wind, h - y)\n",
        "            w_min = min(w_wind, w - x)\n",
        "            if fixed:\n",
        "              if h_min < h_wind or w_min < w_wind:\n",
        "                  continue\n",
        "            window = (x, y, w_min, h_min)\n",
        "            windows.append(window)\n",
        "\n",
        "    return windows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4upB8g262XH"
      },
      "source": [
        "# **1. Load a Sentinel-2 Level-1C tile**\n",
        "\n",
        "In the first step, we lod the input data for the inference process. The input data is a Sentinel2 Level-1C tile which shall be classified with the help of the pre-trained model.\n",
        "\n",
        "Let us define the Python dictionary which holds information about where the Sentinel-2 Level-1C data is stored. Next we'll define `main_path`, `sentinel2_safe_name` and `sentinel2_safe_path`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i8-7-jDSd1p"
      },
      "source": [
        "data_input = {}\n",
        "data_input['main_path'] ='./S2_Tile_based_classification/'\n",
        "\n",
        "data_input['sentinel2_safe_name'] = 'S2AA_MSIL1C_20210331T100021_N0300_R122_T33TTG_20210331T113321.SAFE/'\n",
        "data_input['sentinel3_safe_path'] = data_input['main_path']+'01_input_data/S2_tile_4_inference/'+data_input['sentinel2_safe_name']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLm-Rv0i8rsX"
      },
      "source": [
        "#**2. Resample all bands of a Seninel-2 Level 1-C tile to 10m spatial resolution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VIEJ2tMu_KQ"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGz0oluv89IP"
      },
      "source": [
        "#**3. Reorder the bands according to the order of the pretrained model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YicVi6F9Hqk"
      },
      "source": [
        "#**4. Load the pretrained sequential convolutional neural network based on EuroSAT data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB5OtCYy9NUg"
      },
      "source": [
        "#**5. Divide the Sentinel-2 L1C tile into  64x64 windows**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPbLp7xL9Z8v"
      },
      "source": [
        "#**6. Infer land use classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jYod3ZD9ljF"
      },
      "source": [
        "#**7. Visualize the final classified image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeiHqIzQ9tB9"
      },
      "source": [
        ""
      ]
    }
  ]
}