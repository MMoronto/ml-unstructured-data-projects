{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tile-based classification using Sentinel-2 L1C  and EuroSAT data-Inference.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1ybbQTHScMz7y2Gur32DgQOvoFSKQRtWc",
      "authorship_tag": "ABX9TyPjjEZFu0VmA9UDJiWSd69K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoronto/ml-unstructured-data-projects/blob/master/Tile_based_classification_using_Sentinel_2_L1C_and_EuroSAT_data_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igPDT5gC32Ga"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "This workflow explores the process of infering land use / classification from a pre-trained model based on the benchmark EuroSAT dataset. This note book contains notes I've taken as I work through the example workflows presented in the AI for Earth monitoring MOOC on Futurelearn.\n",
        "\n",
        "This is the second of a two part practice module, the first part of this two part series explores the process of training a convolutional neural network based on EuroSAT benchmark data for land use/land cover classification while the second part explores the workflow for utilising the learned capabilities of our pre-trained model to infer land use / land cover classification on a Sentinel-2 level-1C tile image.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO04EX-h6mJI"
      },
      "source": [
        "## **Data**\n",
        "\n",
        "The inference process utilizes the following data:\n",
        "\n",
        "* a `Sentinel-2 level-1C file`, which is available in the following folder: ./S2_Tile_based_classification/01_input_data/S2_tile_4_inference.\n",
        "The scene shows a coasteal part over Italy on March 31, 20121. The scene is used as input data for the pretrained model in order to infer land use/land cover classes.\n",
        "* a `pretrained  model`, a `convolutional neural network` which has been trained based on EuroSAT  data, as a benchmark dataset for land use / land cover classifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nruaCeA-6p0V"
      },
      "source": [
        "## **Additional Resources**\n",
        "\n",
        "* 3B - Tile-based classification with EuroSAT data - Training\n",
        "* EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification\n",
        "* EuroSAT data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlGo-MO860kU"
      },
      "source": [
        "## **Notebook Outline**\n",
        "\n",
        "* 1 - Load a Sentinel-2 Level 1-C tile\n",
        "* 2 - Resample all bands of a Seninel-2 Level 1-C tile to 10m spatial resolution\n",
        "* 3 - Reorder the bands according to the order of the pretrained model\n",
        "* 4 - Load the pretrained sequential convolutional neural network based on EuroSAT data\n",
        "* 5 - Divide the Sentinel-2 L1C tile into  64x64 windows\n",
        "* 6 - Infer land use classes\n",
        "* 7 - Visualize the final classified image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9YkbgoSV2e"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiqlwo6HDQZ9"
      },
      "source": [
        "## Begin S3FS import snippet ##\n",
        "import os, sys\n",
        "s3_home = os.getcwd()\n",
        "try: sys.path.remove(s3_home) # Remove the S3 root from the path\n",
        "except Exception: pass\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# os.chdir('/home/jovyan') # Temporarily move to another directory\n",
        "\n",
        "# Begin imports #\n",
        "import tensorflow as tf\n",
        "from osgeo import gdal_array, osr, gdal\n",
        "import glob\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot as pyplot\n",
        "import matplotlib.colors\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# end imports #\n",
        "\n",
        "os.chdir(current_dir) # go back to your previous directory\n",
        "\n",
        "sys.path.append(s3_home) # restore the s3 root in the path\n",
        "\n",
        "## end s3fs import snippet ##"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OB5oBwltcVA"
      },
      "source": [
        "## Begin S3FS Import Snippet ##\n",
        "import os, sys\n",
        "s3_home = os.getcwd()\n",
        "try: sys.path.remove(s3_home) # Remove the S3 from the $path\n",
        "except Exception: pass\n",
        "\n",
        "# current_dir = os.getcwd()\n",
        "\n",
        "# os.chdir('/home/jovyan') # Temporarily move to another directory\n",
        "\n",
        "# Begin imports #\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from osgeo import gdal_array\n",
        "from matplotlib import pyplot as pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "# end imports #\n",
        "\n",
        "# os.chdir(current_dir) # go back to your previous dir\n",
        "\n",
        "# sys.path.append(s3_home) # restore the s3 root in the $path\n",
        "\n",
        "## end s3fs import snippet ##\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-DF0lwEWyWk"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3mvsK6CKOO-"
      },
      "source": [
        "from_folder_to_stack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwNtHfldXIaf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "'''\n",
        "function name: \n",
        "    from_folder_to_stack\n",
        "description:\n",
        "    This function transform the .SAFE file into three different arrays (10m, 20m and 60m).\n",
        "Input:\n",
        "    safe_path: the path of the .SAFE file;\n",
        "    data_bands_20m: if True, the function computes stack using Sentinel2 band with 20m of pixel resolution (default=True);\n",
        "    data_bands_60m: if True, the function computes stack using Sentinel2 band with 60m of pixel resolution (default=True);    \n",
        "Output: \n",
        "    stack_10m: stack with the following S2L1C bands (B02,B03,B04,B08)\n",
        "    stack_20m: stack with the following S2L1C bands (B05,B06,B07,B11,B12,B8A)\n",
        "    stack_60m: stack with the following S2L1C bands (B01,B09,B10)\n",
        "'''\n",
        "def from_folder_to_stack(\n",
        "        safe_path,\n",
        "        data_bands_20m=True,\n",
        "        data_bands_60m=True,\n",
        "        ):        \n",
        "    \n",
        "    level_folder_name_list = glob.glob(safe_path + 'GRANULE/*') \n",
        "    level_folder_name = level_folder_name_list[0]\n",
        "    \n",
        "    if level_folder_name.find(\"L2A\") < 0:\n",
        "        safe_path = [level_folder_name + '/IMG_DATA/']\n",
        "    else:\n",
        "        safe_path_10m = level_folder_name + '/IMG_DATA/R10m/'\n",
        "        safe_path = [safe_path_10m]\n",
        "    \n",
        "    text_files = []\n",
        "\n",
        "    for i in range(0,len(safe_path)):\n",
        "        print(\"[AI4EO_MOOC]_log: Loading .jp2 images in %s\" % (safe_path[i]))\n",
        "        text_files_tmp = [f for f in os.listdir(safe_path[i]) if f.endswith('.jp2')]\n",
        "        text_files.append(text_files_tmp)\n",
        "        \n",
        "    lst_stack_60m=[]\n",
        "    lst_code_60m =[]\n",
        "    lst_stack_20m=[]\n",
        "    lst_code_20m =[]\n",
        "    lst_stack_10m=[]\n",
        "    lst_code_10m =[]\n",
        "    for i in range(0,len(safe_path)):        \n",
        "        \n",
        "        print(\"[AI4EO_MOOC]_log: Reading .jp2 files in %s\" % (safe_path[i]))\n",
        "        for name in range(0, len(text_files[i])):            \n",
        "            text_files_tmp = text_files[i]               \n",
        "            if data_bands_60m == True:\n",
        "                cond_60m = ( (text_files_tmp[name].find(\"B01\") > 0) or (text_files_tmp[name].find(\"B09\") > 0) \n",
        "                            or (text_files_tmp[name].find(\"B10\") > 0))\n",
        "                if cond_60m:\n",
        "                    print(\"[AI4EO_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "                    lst_stack_60m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "                    lst_code_60m.append(text_files_tmp[name][24:26])\n",
        "                \n",
        "            if data_bands_20m == True:                    \n",
        "                cond_20m = (text_files_tmp[name].find(\"B05\") > 0) or (text_files_tmp[name].find(\"B06\") > 0) or (\n",
        "                            text_files_tmp[name].find(\"B07\") > 0) or (text_files_tmp[name].find(\"B11\") > 0) or (\n",
        "                                       text_files_tmp[name].find(\"B12\") > 0) or (text_files_tmp[name].find(\"B8A\") > 0)\n",
        "                cond_60m_L2 = (text_files_tmp[name].find(\"B05_60m\") < 0) and (text_files_tmp[name].find(\"B06_60m\") < 0) and (\n",
        "                            text_files_tmp[name].find(\"B07_60m\") < 0) and (text_files_tmp[name].find(\"B11_60m\") < 0) and (\n",
        "                                       text_files_tmp[name].find(\"B12_60m\") < 0) and (text_files_tmp[name].find(\"B8A_60m\") < 0)\n",
        "                cond_20m_tot = cond_20m and cond_60m_L2\n",
        "                if cond_20m_tot:\n",
        "                    print(\"[AI4EO_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "                    lst_stack_20m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "                    lst_code_20m.append(text_files_tmp[name][24:26])\n",
        "            else:\n",
        "                stack_20m = 0\n",
        "                    \n",
        "            cond_10m = (text_files_tmp[name].find(\"B02\") > 0) or (text_files_tmp[name].find(\"B03\") > 0) or (\n",
        "                        text_files_tmp[name].find(\"B04\") > 0) or (text_files_tmp[name].find(\"B08\") > 0)\n",
        "            cond_20m_L2 = (text_files_tmp[name].find(\"B02_20m\") < 0) and (text_files_tmp[name].find(\"B03_20m\") < 0) and (\n",
        "                        text_files_tmp[name].find(\"B04_20m\") < 0) and (text_files_tmp[name].find(\"B08_20m\") < 0)\n",
        "            cond_60m_L2 = (text_files_tmp[name].find(\"B02_60m\") < 0) and(text_files_tmp[name].find(\"B03_60m\") < 0) and(\n",
        "                        text_files_tmp[name].find(\"B04_60m\") < 0) and (text_files_tmp[name].find(\"B08_60m\") < 0)\n",
        "            cond_10m_tot = cond_10m and cond_20m_L2 and cond_60m_L2\n",
        "            \n",
        "            if cond_10m_tot:\n",
        "                print(\"[AI4EO_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "                lst_stack_10m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "                lst_code_10m.append(text_files_tmp[name][24:26])\n",
        "                 \n",
        "    \n",
        "    stack_10m=np.asarray(lst_stack_10m)\n",
        "    sorted_list_10m = ['02','03','04','08']    \n",
        "    print('[AI4EO_MOOC]_log: Sorting stack 10m...')\n",
        "    stack_10m_final_sorted = stack_sort(stack_10m, lst_code_10m, sorted_list_10m)\n",
        "    \n",
        "    stack_20m=np.asarray(lst_stack_20m)\n",
        "    sorted_list_20m = ['05','06','07','11','12','8A']\n",
        "    print('[AI4EO_MOOC]_log: Sorting stack 20m...')\n",
        "    stack_20m_final_sorted = stack_sort(stack_20m, lst_code_20m, sorted_list_20m)\n",
        "    \n",
        "    stack_60m=np.asarray(lst_stack_60m)\n",
        "    sorted_list_60m = ['01','09','10']    \n",
        "    print('[AI4EO_MOOC]_log: Sorting stack 60m...')\n",
        "    stack_60m_final_sorted = stack_sort(stack_60m, lst_code_60m, sorted_list_60m)\n",
        "                \n",
        "    return stack_10m_final_sorted, stack_20m_final_sorted, stack_60m_final_sorted"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwSv2ExkGK9e"
      },
      "source": [
        "stack_sort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW6E0LvU_wB0"
      },
      "source": [
        "def stack_sort(stack_in, lst_code, sorted_list):\n",
        "  b, r, c = stack_in.shape\n",
        "  stack_sorted = np.zeros((r,c,b), dtype=np.uint16)\n",
        "\n",
        "  len_list_bands = len(lst_code)\n",
        "\n",
        "  c = np.zeros((len_list_bands), dtype=np.uint8)\n",
        "  count = 0\n",
        "  count_sort = 0\n",
        "  while count_sort != len_list_bands:\n",
        "    if lst_code[count] == sorted_list[count_sort]:\n",
        "      c[count_sort] = count\n",
        "      count_sort = count_sort + 1\n",
        "      count = 0\n",
        "    else:\n",
        "      count = count + 1\n",
        "    print('[AI4EO_MOOC]_log: sorted list:', sorted_list)\n",
        "    print('[AI4EO_MOOC]_log: bands:', c)\n",
        "    for i in range(0, len_list_bands):\n",
        "        stack_sorted[:,:,i]=stack_in[c[i],:,:]\n",
        "    \n",
        "    return stack_sorted"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYkZZV_IrQs"
      },
      "source": [
        "resample_3d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS-jKoKI8uK"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  resample_3d\n",
        "description:\n",
        "  wrapper of ndimage zoom. Bilinear interpolation for resampling array\n",
        "input:\n",
        "  stack: array to be resampled;\n",
        "  row10m: the expected row;\n",
        "  col10m: the expected col;\n",
        "  rate: the rate of the transformation;\n",
        "output:\n",
        "  stack_10m: resampled array\n",
        "'''\n",
        "def resample_3d(\n",
        "        stack,\n",
        "        row10m,\n",
        "        col10m,\n",
        "        rate):\n",
        "    row, col, bands = stack.shape\n",
        "    print(\"[AI4EO_MOOC]_log: Array shape (%d,%d,%d)\" % (row, col, bands))\n",
        "\n",
        "    stack_10m = np.zeros((row10m, col10m, bands),dtype=np.uint16)\n",
        "    print(\"[AI4EO_MOOC]_log: Resize array bands from (%d,%d,%d) to (%d,%d,%d)\" % (\n",
        "        row, col, bands, row10m, col10m, bands))\n",
        "    \n",
        "    for i in range(0, bands):\n",
        "      stack_10m[:, :, i] = ndimage.zoom(stack[:, :,i], rate)\n",
        "\n",
        "    del (stack)\n",
        "\n",
        "    return stack_10m"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0Kp7sWIwPk"
      },
      "source": [
        "sentinel2_format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3mAuYCJAO-"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  sentinel2_format\n",
        "description:\n",
        "  This function transforms the multistack into sentinel2 format arrays with bands in the right positions for our AI model.\n",
        "input:\n",
        "  total_stack: array that is the concatenation of stack10, stack_20mTo10m and stack_60mTo10m.\n",
        "output:\n",
        "  sentinel2: sentinel2 format array\n",
        "'''\n",
        "def sentinel2_format(\n",
        "        total_stack):\n",
        "  \n",
        "    row_tot, col_tot, bands_tot = total_stack.shape\n",
        "    sentinel2 = np.zeros((row_tot, col_tot, bands_tot),dtype=np.uint16)\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Creating a total stack with following list of bands:\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 1 - Coastal aerosol\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 2 - Blue\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 3 - Green\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 4 - Red\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 5 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 6 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 7 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8 - NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8A - Narrow NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 9 - Water vapour\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 10 - SWIR - Cirrus\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 11 - SWIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 12 - SWIR\")\n",
        "\n",
        "    sentinel2[:, :, 0] = total_stack[:, :, 10]\n",
        "    sentinel2[:, :, 1] = total_stack[:, :, 0]\n",
        "    sentinel2[:, :, 2] = total_stack[:, :, 1]\n",
        "    sentinel2[:, :, 3] = total_stack[:, :, 2]\n",
        "    sentinel2[:, :, 4] = total_stack[:, :, 4]\n",
        "    sentinel2[:, :, 5] = total_stack[:, :, 5]\n",
        "    sentinel2[:, :, 6] = total_stack[:, :, 6]\n",
        "    sentinel2[:, :, 7] = total_stack[:, :, 3]\n",
        "    sentinel2[:, :, 8] = total_stack[:, :, 9]\n",
        "    sentinel2[:, :, 9] = total_stack[:, :, 11]\n",
        "    sentinel2[:, :, 10] = total_stack[:, :, 12]\n",
        "    sentinel2[:, :, 11] = total_stack[:, :, 7]\n",
        "    sentinel2[:, :, 12] = total_stack[:, :, 8]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_P1HyB9I3Y8"
      },
      "source": [
        "sliding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfdgOtpfI-TY"
      },
      "source": [
        "'''\n",
        "Function_name:\n",
        "  sliding\n",
        "description:\n",
        "input:\n",
        "  shape: the target shape\n",
        "  window_size: the shape of the window\n",
        "  step-size:\n",
        "  fixed\n",
        "output:\n",
        "  windows:\n",
        "'''\n",
        "\n",
        "def sliding(shape, window_size, step_size=None, fixed=True):\n",
        "    \n",
        "    h, w = shape\n",
        "    if step_size:\n",
        "        h_step = step_size\n",
        "        w_step = step_size\n",
        "    else:\n",
        "        h_step = window_size\n",
        "        w_step = window_size\n",
        "        \n",
        "    h_wind = window_size\n",
        "    w_wind = window_size\n",
        "    windows = []\n",
        "    for y in range(0, h, h_step):\n",
        "        for x in range(0, w, w_step):\n",
        "            h_min = min(h_wind, h - y)\n",
        "            w_min = min(w_wind, w - x)\n",
        "            if fixed:\n",
        "                if h_min < h_wind or w_min < w_wind:\n",
        "                    continue\n",
        "            window = (x, y, w_min, h_min)\n",
        "            windows.append(window)\n",
        "\n",
        "    return windows"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4upB8g262XH"
      },
      "source": [
        "# **1. Load a Sentinel-2 Level-1C tile**\n",
        "\n",
        "In the first step, we lod the input data for the inference process. The input data is a Sentinel2 Level-1C tile which shall be classified with the help of the pre-trained model.\n",
        "\n",
        "Let us define the Python dictionary which holds information about where the Sentinel-2 Level-1C data is stored. Next we'll define `main_path`, `sentinel2_safe_name` and `sentinel2_safe_path`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i8-7-jDSd1p"
      },
      "source": [
        "data_input = {}\n",
        "data_input['main_path'] ='/content/drive/MyDrive/Land Classification/S2_Tile_based_classification/'\n",
        "\n",
        "data_input['sentinel2_safe_name'] = 'S2A_MSIL1C_20210331T100021_N0300_R122_T33TTG_20210331T113321.SAFE/'\n",
        "data_input['sentinel2_safe_path'] = data_input['main_path']+'01_Input_data/S2_tile_4_inference/' + data_input['sentinel2_safe_name']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvbReGKCpFXm"
      },
      "source": [
        "The next step makes use of the `function from_folder_to_stack()`. The functions transforms the Sentinel-2 Level-1C file which is disseminated in the `.SAFE` format into three different arrays, each combining the bands with the same spatial resolution. Sentinel-2 samples 13 spectral bands, which have three different resolutions:`10m, 20m and 60m`.\n",
        "\n",
        "The result of the function are three stacked arrays:\n",
        "\n",
        "* `stack_10m`: stack combining bands with 10m spatial resolution `(B02, B03, B04, B08)\n",
        "* `stack_20m`: stack combining bands with 20m spatial resolution `(B05, B06, B07, B11, B12, B8A)\n",
        "* `stack_60m`: stack combining bands with 60m spatial resolution `(B01, B09, B10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmcdhnv7ptht",
        "outputId": "f247e749-159f-426b-aac3-9d1ecb8f1de2"
      },
      "source": [
        "import numpy as np\n",
        "safe_path = data_input['sentinel2_safe_path']\n",
        "stack_10m, stack_20m, stack_60m = from_folder_to_stack(safe_path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Loading .jp2 images in /content/drive/MyDrive/Land Classification/S2_Tile_based_classification/01_Input_data/S2_tile_4_inference/S2A_MSIL1C_20210331T100021_N0300_R122_T33TTG_20210331T113321.SAFE/GRANULE/L1C_T33TTG_A030149_20210331T100404/IMG_DATA/\n",
            "[AI4EO_MOOC]_log: Reading .jp2 files in /content/drive/MyDrive/Land Classification/S2_Tile_based_classification/01_Input_data/S2_tile_4_inference/S2A_MSIL1C_20210331T100021_N0300_R122_T33TTG_20210331T113321.SAFE/GRANULE/L1C_T33TTG_A030149_20210331T100404/IMG_DATA/\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B10.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B09.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B01.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B05.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B07.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B06.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B11.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B8A.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B12.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B03.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B04.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B08.jp2\n",
            "[AI4EO_MOOC]_log: Using .jp2 image: T33TTG_20210331T100021_B02.jp2\n",
            "[AI4EO_MOOC]_log: Sorting stack 10m...\n",
            "[AI4EO_MOOC]_log: sorted list: ['02', '03', '04', '08']\n",
            "[AI4EO_MOOC]_log: bands: [0 0 0 0]\n",
            "[AI4EO_MOOC]_log: Sorting stack 20m...\n",
            "[AI4EO_MOOC]_log: sorted list: ['05', '06', '07', '11', '12', '8A']\n",
            "[AI4EO_MOOC]_log: bands: [0 0 0 0 0 0]\n",
            "[AI4EO_MOOC]_log: Sorting stack 60m...\n",
            "[AI4EO_MOOC]_log: sorted list: ['01', '09', '10']\n",
            "[AI4EO_MOOC]_log: bands: [0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ilFKkIVQwXf"
      },
      "source": [
        "On inspecting the dimensions of the three stacked arrays, we 'll notice that the stack combining bands with 10m resolution consists of 4 bands. The one combining bands with 20m resolution consists of 6 bands and the one combining bands with 60m resolution consists of 3 bands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTBtVvysQyOI",
        "outputId": "0e73b676-d507-4ab6-bc68-a50f93bf7795"
      },
      "source": [
        "print(stack_10m.shape)\n",
        "print(stack_20m.shape)\n",
        "print(stack_60m.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10980, 10980, 4)\n",
            "(5490, 5490, 6)\n",
            "(1830, 1830, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLm-Rv0i8rsX"
      },
      "source": [
        "#**2. Resample all bands of a Sentinel-2 Level 1-C tile to 10m spatial resolution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiHPX_jipptE"
      },
      "source": [
        "In the next step we resample the arrays containing bands with 20m and 60m resolution. You can use the function `resample_3d()` to achive this. The function takes the following keyword arguments:\n",
        "\n",
        "* `stack`: array to be resampled to 10m\n",
        "* `row10m`: number of rows of the 10m resolution array\n",
        "* `col10m`: number of columns of the 10m resolution array\n",
        "* `rate`: to which rate the input stack shall be resampled\n",
        "\n",
        "We have to apply the function to both array stacks, `stack_20m` and `stack_60m`. This results in all three stacks having the same spatial resolution of 10m."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VIEJ2tMu_KQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a54fb99-9480-4fa7-87e2-919436cbe8b4"
      },
      "source": [
        "n_row, n_col, b10 = stack_10m.shape\n",
        "\n",
        "print('[AI4EO_MOOC]_log: Resampling stack with 20 m pixel size...')\n",
        "stack_20mTo10m = resample_3d(stack = stack_20m,\n",
        "                             row10m = n_row,\n",
        "                             col10m = n_col,\n",
        "                             rate= 2)\n",
        "\n",
        "print('[AI4EO_MOOC]_log: Resampling stack with 60 m pixel size...')\n",
        "stack_60mTo10m = resample_3d(stack = stack_60m,\n",
        "                             row10m = n_row,\n",
        "                             col10m = n_col,\n",
        "                             rate= 6)\n",
        "\n",
        "print(stack_20mTo10m.shape)\n",
        "print(stack_60mTo10m.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Resampling stack with 20 m pixel size...\n",
            "[AI4EO_MOOC]_log: Array shape (5490,5490,6)\n",
            "[AI4EO_MOOC]_log: Resize array bands from (5490,5490,6) to (10980,10980,6)\n",
            "[AI4EO_MOOC]_log: Resampling stack with 60 m pixel size...\n",
            "[AI4EO_MOOC]_log: Array shape (1830,1830,3)\n",
            "[AI4EO_MOOC]_log: Resize array bands from (1830,1830,3) to (10980,10980,3)\n",
            "(10980, 10980, 6)\n",
            "(10980, 10980, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGz0oluv89IP"
      },
      "source": [
        "#**3. Reorder the bands according to the order of the pretrained model**\n",
        "\n",
        "The three array stack now have the same spatial resolution. In a next step, we'll concatenate them with the numpy function `concatenate`. We want to concatenate them on the band dimensions (axis=2). The result is one array with a spatial resolution of 10m and 13 bands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMY0AAOLG9dR",
        "outputId": "1593826f-0a2d-4780-ae14-8c6b3d8eb0e0"
      },
      "source": [
        "print('[AI4EO_MOOC]_log: Creating multistack with 10-20-60 m pixel size')\n",
        "\n",
        "total_stack=np.concatenate((stack_10m, stack_20mTo10m, stack_60mTo10m),\n",
        "                           axis=2)\n",
        "\n",
        "total_stack.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Creating multistack with 10-20-60 m pixel size\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10980, 10980, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r22YiboHswz"
      },
      "source": [
        "We can now plot the reflectance for each band for one pixel with matplotlib's `plot()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "b1q-1g6iH-zK",
        "outputId": "823d5b58-5753-4258-eb85-dc43f09ecd70"
      },
      "source": [
        "plt.ylabel(\"Refelectance\")\n",
        "plt.xlabel(\"Band\")\n",
        "plt.plot(total_stack[200,200,:],'-o')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0496a54fd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZORWHvv2O86"
      },
      "source": [
        "The next step involves arranging the Sentinel-2 bands and bringing them to the correct position for the pre-trained model. The function `sentinel2_format` helps bring the bands into the correct order for the model. You want to arrange the bands into the following order:    \n",
        "\n",
        "* `Band 1 - Coastal aerosol` <-- `S2L1 Band 10`\n",
        "\n",
        "* `Band 2 - Blue` <-- `S2L1 Band 0`\n",
        "\n",
        "* `Band 3 - Green` <-- `S2L1 Band 1`\n",
        "\n",
        "* `Band 4 - Red` <-- `S2L1 Band 10`\n",
        "\n",
        "* `Band 5 - Vegetation red edge` <-- `S2L1 Band 4`\n",
        "\n",
        "* `Band 6 - Vegetation red edge` <-- `S2L1 Band 5`\n",
        "\n",
        "* `Band 7 - Vegetation red edge` <-- `S2L1 Band 6`\n",
        "\n",
        "* `Band 8 - NIR` <-- `S2L1 Band 3`\n",
        "\n",
        "* `Band 8A - Narrow NIR` <-- `S2L1 Band 9`\n",
        "\n",
        "* `Band 9 -  Water Vapor` <-- `S2L1 Band 11`\n",
        "\n",
        "* `Band 10 - SWIR - Cirrus` <-- `S2L1 Band 12`\n",
        "\n",
        "* `Band 11 - SWIR` <-- `S2L1 Band 7`\n",
        "\n",
        "* `Band 12 - SWIR` <-- `S2L1 Band 8`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0og83flj4otq",
        "outputId": "665e85cd-354d-4d6e-8ffb-f9745dad509f"
      },
      "source": [
        "s2_arr = sentinel2_format(total_stack)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Creating a total stack with following list of bands:\n",
            "[AI4EO_MOOC]_log: Band 1 - Coastal aerosol\n",
            "[AI4EO_MOOC]_log: Band 2 - Blue\n",
            "[AI4EO_MOOC]_log: Band 3 - Green\n",
            "[AI4EO_MOOC]_log: Band 4 - Red\n",
            "[AI4EO_MOOC]_log: Band 5 - Vegetation red edge\n",
            "[AI4EO_MOOC]_log: Band 6 - Vegetation red edge\n",
            "[AI4EO_MOOC]_log: Band 7 - Vegetation red edge\n",
            "[AI4EO_MOOC]_log: Band 8 - NIR\n",
            "[AI4EO_MOOC]_log: Band 8A - Narrow NIR\n",
            "[AI4EO_MOOC]_log: Band 9 - Water vapour\n",
            "[AI4EO_MOOC]_log: Band 10 - SWIR - Cirrus\n",
            "[AI4EO_MOOC]_log: Band 11 - SWIR\n",
            "[AI4EO_MOOC]_log: Band 12 - SWIR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgg9iHQB5Cnl"
      },
      "source": [
        "Now, we can plot the reflectance for each of the bands for the same pixel as above and we can now easily identify it as a water pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "YjNHxC-25mq8",
        "outputId": "b2ad0156-5336-459b-aa7d-e3a3d1f6abc2"
      },
      "source": [
        "plt.ylabel(\"Reflectance\")\n",
        "plt.xlabel(\"Band\")\n",
        "plt.plot(s2_arr[200,200,:],'-o')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-47e8fa8218aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reflectance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Band\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the reflectances of and see higher reflectances over bands 6 to 8, which are the channels for vegetation."
      ],
      "metadata": {
        "id": "__wcJClCLtdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.ylabel(\"Reflectance\")\n",
        "plt.xlabel('Band')\n",
        "plt.plot(s2_arr[10000,10000,:],'-o')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "-7GPhisBL6Y7",
        "outputId": "8079a544-62f3-4b1d-c8b9-10ff97cd2917"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-de22da840b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reflectance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Band'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YicVi6F9Hqk"
      },
      "source": [
        "#**4. Load the pretrained sequential convolutional neural network based on EuroSAT data**\n",
        "\n",
        "Next, you can load the pre-trained model which has been trained in the notebook 3B_tile-based_classification_with_EuroSAT_data_training. The function `load_model()` from the class `keras.models` allows you to load a model in the Keras format `H5`. With `model.summary()` you can get tabular overview of the model architecture. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3kQmzm10tuY",
        "outputId": "c216d0d5-66d1-4ee0-9e6e-9775390d39b2"
      },
      "source": [
        "data_input['pre_trained_model_name'] = 'keras_sentinel2_classification_trained_model_e50_9190.h5'\n",
        "data_input['pre_trained_model_path'] = data_input['main_path'] + '02_pretrained_model/'\n",
        "\n",
        "model = tf.keras.models.load_model(data_input['pre_trained_model_path'] + data_input['pre_trained_model_name'])\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 32)        3776      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 62, 62, 32)        9248      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 62, 62, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 31, 31, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 31, 31, 64)        18496     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 29, 29, 64)        36928     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               6423040   \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,496,618\n",
            "Trainable params: 6,496,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB5OtCYy9NUg"
      },
      "source": [
        "#**5. Divide the Sentinel-2 L1C tile into  64x64 windows**\n",
        "\n",
        "SInce the Convolutional Neural Network has been trained on EuroSAT benchmark data, which have a dimension of `[13, 64, 64]`, the trained model can only predict on `64x64 pixel` subsets (so-called chips).\n",
        "\n",
        "We can apply the function `sliding()`, which divides the Sentinel-2 image with a dimension of `10980 x 10980 pixels` into multiple subsets with a size of `64 x 64 pixels`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "CfmouY01pgHE",
        "outputId": "e6ebc4de-a70d-4d51-dc0b-369919016f21"
      },
      "source": [
        "print('[AI4EO_MOOC]_log: Divide all images into windows for the inference step')\n",
        "\n",
        "target_shape = (s2_arr.shape[0], s2_arr.shape[1])\n",
        "windows = sliding(target_shape, 64, fixed=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Divide all images into windows for the inference step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-1a0c4eab61d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[AI4EO_MOOC]_log: Divide all images into windows for the inference step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms2_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mwindows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPbLp7xL9Z8v"
      },
      "source": [
        "#**6. Infer land use classes**\n",
        "\n",
        "The next step is the inference process. In this step we apply the loaded model and predict the probabilities of each of the ten land use classes for each pixel. Let's define some variables that help us specify the parameters for the inference process.  Let us define `batch_size=10`, which specifies the number of parallel computations and also reduces the number of iterations during the inference process by a factor of 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "PnSgPEbQqXma",
        "outputId": "efbced51-ef56-4859-e3fd-9f6a485c0af0"
      },
      "source": [
        "windows_ = iter(windows)\n",
        "windows_class = iter(windows)\n",
        "\n",
        "batch_size = 10\n",
        "total_chips = len(windows)\n",
        "num_steps = int(total_chips / batch_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d7475d73e024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwindows_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwindows_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal_chips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'windows' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHd_fnUwxv4p"
      },
      "source": [
        "In the next step, we go through each `64 x 64 pixel` window(chip), retrieve the channel information of the Sentinel-2 image and predict the land cover classes for each chip with the function `model.predict()`. The prediction results return the probability of each land use class for each pixel. With numpy function `argmax()`, we can select the class with the highest predicted probability.\n",
        "\n",
        "The last step involves graduall;y building up the final image `img_classes` with the predicted land use  classes and a dimension of `(10980 x 10980)`, based on the `64 x 64 pixel` windows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaebNf1UxwoF"
      },
      "source": [
        "print('[AI4EO_MOOC]_log: Inference step...')\n",
        "\n",
        "img_classes = np.zeros((total_stack.shape[0], total_stack.shape[1]), dtype=np.uint8)\n",
        "\n",
        "predictions = []\n",
        "progbar = tf.keras.utils.Progbar(num_steps)\n",
        "\n",
        "for b in range(num_steps):\n",
        "    chips = np.empty([batch_size, 64, 64, 13])\n",
        "    for k in range(batch_size):\n",
        "        ymin, xmin, xmax, ymax = next(windows_)\n",
        "        chips[k] = s2_arr[xmin:xmin+xmax, ymin:ymin+ymax, :]\n",
        "\n",
        "    preds = model.predict(chips)\n",
        "    predictions.append(np.argmax(preds, axis=-1))\n",
        "    for i in range(0, batch_size):\n",
        "        ymin_cl. xmin_cl, xmax_cl, ymax_cl = next(windows_class)\n",
        "        img_classes[xmin_cl:xmin_cl+xmax_cl, ymin_cl:ymin_cl+ymax_cl] = predictions[b][i]\n",
        "    progbar.update(b + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jYod3ZD9ljF"
      },
      "source": [
        "#**7. Visualize the final classified image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeiHqIzQ9tB9"
      },
      "source": [
        "In this final step, we'll visualize the classified image after running the inference on our images. We can use matplotlib's function `imshow()` to visualize the predicted array `img_classes`. For readability, we can define class labels (`label`) and a customized color scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH2jxhqq2yRN"
      },
      "source": [
        "label=['AnnualCrop','Forest','HerbaceousVegetation','Highway','Industrial',\n",
        "       'Pasture','PermanentCrop','Residential','River','SeaLake']\n",
        "\n",
        "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n",
        "    \"\", \n",
        "    [\"linen\",\"darkgreen\",\"lime\",\"grey\",\"k\",\n",
        "     \"olive\",\"darkgoldenrod\",\"lightgrey\",\"azure\",\"lightblue\"])\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img_classes, cmap=cmap)\n",
        "cbar=plt.colorbar()\n",
        "cbar.ax.set_yticklabels(label)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}