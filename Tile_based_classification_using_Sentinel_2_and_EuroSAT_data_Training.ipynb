{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tile-based classification using Sentinel-2 and EuroSAT data-Training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Nb6axbd2makj-lAkYy_81CqLwf8aKOQ9",
      "authorship_tag": "ABX9TyNbPYV10onF4494L8kL8e0v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoronto/ml-unstructured-data-projects/blob/master/Tile_based_classification_using_Sentinel_2_and_EuroSAT_data_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeFaI7puszgm"
      },
      "source": [
        "##**Intro**\n",
        "\n",
        "This workflow explores the process of training a `Convolutional Neural Network (CNN)` with Keras based on the benchmark dataset EuroSAT. This noote book contains notes I've taken as I work through the example workflow presented in the AI for Earth monitoring MOOC on Futurelearn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkSeuefswyfX"
      },
      "source": [
        "##**Machine-Learning Algorithm**\n",
        "\n",
        "This example develops a `Sequential Convolutional Neural Network (CNN)` with TF Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyS5FFHUxcN_"
      },
      "source": [
        "##**Data**\n",
        "The model is trained on the EuroSAT benchmark dataset which is based on Sentinel-2 satellite images and consists of 27,000 labeled and geo-referenced images.The dataset provides information on the following ten land cover/land use cases:\n",
        "* `Annual Crop`\n",
        "* `Forest`\n",
        "* `Herbaceous Vegetation`\n",
        "* `Highway`\n",
        "* Industrial`\n",
        "* `Pasture`\n",
        "* `Permanent Crop`\n",
        "* `Residential`\n",
        "* `River`\n",
        "* `Sea Lake`\n",
        "\n",
        "The benchmark dataset can be used to detect `land cover / land use changes`. The geo-referenced datasset EuroSAT is publicly accessible here: https://github.com/phelber/eurosat\n",
        "\n",
        "## Notebook Outline\n",
        "* 1 - Load the EuroSAT benchmark dataset as input data\n",
        "* 2 - Create training and test subsets from input data\n",
        "* 3 - Define the Convolutional Neural Network architecture\n",
        "* 4 - Fit (train) the convolutional neural network (CNN)\n",
        "* 5 - Evaluate the performance of the CNN model with a confusion matrix\n",
        "\n",
        "\n",
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsppuKATLSor"
      },
      "source": [
        "## Begin S3FS Import Snippet ##\n",
        "import os, sys\n",
        "s3_home = os.getcwd()\n",
        "try: sys.path.remove(s3_home) # Remove the S3 from the $path\n",
        "except Exception: pass\n",
        "\n",
        "# current_dir = os.getcwd()\n",
        "\n",
        "# os.chdir('/home/jovyan') # Temporarily move to another directory\n",
        "\n",
        "# Begin imports #\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from osgeo import gdal_array\n",
        "from matplotlib import pyplot as pyplot\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "# end imports #\n",
        "\n",
        "# os.chdir(current_dir) # go back to your previous dir\n",
        "\n",
        "# sys.path.append(s3_home) # restore the s3 root in the $path\n",
        "\n",
        "## end s3fs import snippet ##\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttI_pu8vzd8_"
      },
      "source": [
        "# !unzip \"drive/MyDrive/Land Classification/S2_Tile_based_classification.zip\" -d \"drive/MyDrive/Land Classification/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-DF0lwEWyWk"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3mvsK6CKOO-"
      },
      "source": [
        "from_folder_to_stack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwNtHfldXIaf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "'''\n",
        "function name:\n",
        "  from_folder_to_stack\n",
        "description:\n",
        "  This function transforms the .SAFE file into three different arrays (10m, 20m and 60m).\n",
        "Input:\n",
        "  safe_path: the path of the .SAFE file;\n",
        "  data_bands_20m: if True, the fumnction computes stack using Sentinel2 band with 20m of pixel resolution (default=True);\n",
        "  data_bands_60m: if True, the function computes stack using Sentinel2 band with 60m of pixel resolution (default=True);\n",
        "Output:\n",
        "  stack_10m: stack with the following S2L1C bands (B02, B03, B04, B08)\n",
        "  stack_20m: stack with the following S2L1C bands (B05, B06, B07, B11, B12, B8A)\n",
        "  stack_60m: stack with the following S2L1C bands (B01, mB09, B10)\n",
        "'''\n",
        "def from_folder_to_stack(\n",
        "    safe_path,\n",
        "    data_bands_20m=True,\n",
        "    data_bands_60m=True,\n",
        "    ):\n",
        "\n",
        "  level_folder_name_list = glob.glob(safe_path + 'GRANULE/*')\n",
        "  level_folder_name = level_folder_name_list[0]\n",
        "\n",
        "  if level_folder_name.find(\"L2A\") < 0:\n",
        "    safe_path = [level_folder_name + '/IMG_DATA/']\n",
        "  else:\n",
        "    safe_path_10m = level_folder_name + '/IMG_DATA/R10m/'\n",
        "    safe_path = [safe_path_10m]\n",
        "\n",
        "  text_files = []\n",
        "\n",
        "  for i in range(0, len(safe_path)):\n",
        "      print(\"[AI4EO_MOOC]_log: Loading .jp2 images in %s\" % (safe_path[i]))\n",
        "      text_files_tmp = [f for f in os.listdir(safe_path[i]) if f.endswith('.jp2')]\n",
        "      text_files.append(text_files_tmp)\n",
        "\n",
        "  lst_stack_60m=[]\n",
        "  lst_code_60m=[]\n",
        "  lst_stack_20m=[]\n",
        "  lst_code_20m=[]\n",
        "  lst_stack_10m=[]\n",
        "  lst_code_10m=[]\n",
        "  for i in range(0, len(safe_path)):\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Reading .jp2 files in %s\" % (safe_path[i]))\n",
        "    for name in range(0, len(text_files[i])):\n",
        "      text_files_tmp = text_files[i]\n",
        "      if data_bands_60m == True:\n",
        "        cond_60m = ( (text_files_tmp[name].find(\"B01\") > 0) or (text_files_tmp[name].find(\"B09\") > 0)\n",
        "                    or (text_files_tmp[name].find(\"B10\") > 0))\n",
        "        if cond_60m:\n",
        "            print(\"[AI4EO_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "            lst_stack_60m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "            lst_code_60m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "      if data_bands_20m == True:\n",
        "          cond_20m = (text_files_tmp[name].find(\"B05\") > 0) or (text_files_tmp[name].find(\"B06\") > 0) or (\n",
        "                      text_files_tmp[name].find(\"B07\") > 0) or (text_files_tmp[name].find(\"B11\") > 0) or (\n",
        "                                  text_files_tmp[name].find(\"B12\") > 0) or (text_files_tmp[name].find(\"B8A\") > 0)\n",
        "          cond_60m_L2 = (text_files_tmp[name].find(\"B05_60m\") < 0) and (text_files_tmp[name].find(\"B06_60m\") < 0) and (\n",
        "                      text_files_tmp[name].find(\"B07_60m\") < 0) and (text_files_tmp[name].find(\"B11_60m\") < 0) and (\n",
        "                                  text_files_tmp[name].find(\"B12_60m\") < 0) and (text_files_tmp[name].find(\"B8A_60m\") < 0)\n",
        "          cond_20m_tot = cond_20m and cond_60m_L2\n",
        "          if cond_20m_tot:\n",
        "              print(\"[AI4E_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "              lst_stack_20m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "              lst_code_20m.append(text_files_tmp[name][24:26])\n",
        "      else:\n",
        "        stack_20m = 0\n",
        "\n",
        "      cond_10m = (text_files_tmp[name].find(\"B02\") > 0) or (text_files_tmp[name].find(\"B03\") > 0) or (\n",
        "                  text_files_tmp[name].find(\"B04\") > 0) or (text_files_tmp[name].find(\"B08\") > 0)\n",
        "      cond_20m_L2 = (text_files_tmp[name].find(\"B02_20m\") < 0) and (text_files_tmp[name].find(\"B03_20m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_20m\") < 0) and (text_files_tmp[name].find(\"B08_20m\") < 0)\n",
        "      cond_60m_L2 = (text_files_tmp[name].find(\"B02_60m\") < 0) and (text_files_tmp[name].find(\"B03_60m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_60m\") < 0) and (text_files_tmp[name].find(\"B08_60m\") < 0)\n",
        "      cond_10m_tot = cond_10m and cond_20m_L2 and cond_60m_L2\n",
        "\n",
        "      if cond_10m_tot:\n",
        "          print(\"[AI4E)_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "          lst_stack_10m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "          lst_code_10m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "\n",
        "  stack_10m=np.asarray(lst_stack_10m)\n",
        "  sorted_list_10m = ['02', '03', '04', '08']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 10m...')\n",
        "  stack_10m_final_sorted = stack_sort(stack_10m, lst_code_10m, sorted_list_10m)\n",
        "\n",
        "  stack_20m=np.asarray(lst_stack_20m)\n",
        "  sorted_list_20m = ['05', '06', '07', '11', '12', '8A']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 20m...')\n",
        "  stack_20m_final_sorted = stack_sort(stack_20m, lst_code_20m, sorted_list_20m)\n",
        "              \n",
        "  stack_60m=np.asarray(lst_stack_60m)\n",
        "  sorted_list_60m = ['01', '09', '10']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 60m...')\n",
        "  stack_60m_final_sorted = stack_sort(stack_60m, lst_code_60m, sorted_list_60m)\n",
        "\n",
        "  return stack_10m_final_sorted, stack_20m_final_sorted, stack_60m_final_sorted"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwSv2ExkGK9e"
      },
      "source": [
        "stack_sort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW6E0LvU_wB0"
      },
      "source": [
        "def stack_sort(stack_in, lst_code, sorted_list):\n",
        "  b, r, c = stack_in.shape\n",
        "  stack_sorted = np.zeros((r,c,b), dtype=np.unit16)\n",
        "\n",
        "  len_list_bands = len(lst_code)\n",
        "\n",
        "  c = np.zeros((len_list_bands), dtype=np.unit8)\n",
        "  count = 0\n",
        "  count_sort = 0\n",
        "  while count_sort != len_list_bands:\n",
        "    if lst_code[count] == sorted_list[count_sort]:\n",
        "      c[count_sort] = count\n",
        "      count_sort = count_sort + 1\n",
        "      count = 0\n",
        "    else:\n",
        "      count = count + 1\n",
        "    print('[AI4EO_MOOC]_log: sorted list:', sorted_list)\n",
        "    print('[AI4EO_MOOC]_log: bands:', c)\n",
        "    for i in range(0, len_list_bands):\n",
        "        stack_sorted[:,:,i]=stack_in[c[i],:,:]\n",
        "    \n",
        "    return stack_sorted"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYkZZV_IrQs"
      },
      "source": [
        "resample_3d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS-jKoKI8uK"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  resample_3d\n",
        "description:\n",
        "  wrapper of ndimage zoom. Bilinear interpolation for resampling array\n",
        "input:\n",
        "  stack: array to be resampled;\n",
        "  row10m: the expected row;\n",
        "  col10m: the expected col;\n",
        "  rate: the rate of the transformation;\n",
        "output:\n",
        "  stack_10m: resampled array\n",
        "'''\n",
        "def resample_3d(\n",
        "        stack,\n",
        "        row10m,\n",
        "        col10m,\n",
        "        rate):\n",
        "    row, col, bands = stack.shape\n",
        "    print(\"[AI4EO_MOOC]_log: Array shape (%d,%d,%d)\" % (row, col, bands))\n",
        "\n",
        "    stack_10m = np.zeros((row10m, col10m, bands),dtype=np.uint16)\n",
        "    print(\"[AI4EO_MOOC]_log: Resize array bands from (%d,%d,%d) to (%d,%d,%d)\" % (\n",
        "        row, col, bands, row10m, col10m, bands))\n",
        "    \n",
        "    for i in range(0, bands):\n",
        "      stack_10m[:, :, i] = ndimage.zoom(stack[:, :,i], rate)\n",
        "\n",
        "    del (stack)\n",
        "\n",
        "    return stack_10m"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0Kp7sWIwPk"
      },
      "source": [
        "sentinel2_format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3mAuYCJAO-"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  sentinel2_format\n",
        "description:\n",
        "  This function transforms the multistack into sentinel2 format arrays with bands in the right positions for our AI model.\n",
        "input:\n",
        "  total_stack: array that is the concatenation of stack10, stack_20mTo10m and stack_60mTo10m.\n",
        "output:\n",
        "  sentinel2: sentinel2 format array\n",
        "'''\n",
        "def sentinel2_format(\n",
        "        total_stack):\n",
        "  \n",
        "    row_tot, col_tot, bands_tot = total_stack.shape\n",
        "    sentinel2 = np.zeros((row_tot, col_tot, bands_tot),dtype=np.unit16)\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Creating a total stack with following list of bands:\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 1 - Coastal aerosol\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 2 - Blue\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 3 - Green\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 4 - Red\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 5 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 6 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 7 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8 - NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8A - Narrow NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 9 - Water vapour\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 10 - SWIR - Cirrus\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 11 - SWIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 12 - SWIR\")\n",
        "\n",
        "    sentinel2[:, :, 0] = total_stack[:, :, 10]\n",
        "    sentinel2[:, :, 1] = total_stack[:, :, 0]\n",
        "    sentinel2[:, :, 2] = total_stack[:, :, 1]\n",
        "    sentinel2[:, :, 3] = total_stack[:, :, 2]\n",
        "    sentinel2[:, :, 4] = total_stack[:, :, 4]\n",
        "    sentinel2[:, :, 5] = total_stack[:, :, 5]\n",
        "    sentinel2[:, :, 6] = total_stack[:, :, 6]\n",
        "    sentinel2[:, :, 7] = total_stack[:, :, 3]\n",
        "    sentinel2[:, :, 8] = total_stack[:, :, 9]\n",
        "    sentinel2[:, :, 9] = total_stack[:, :, 11]\n",
        "    sentinel2[:, :, 10] = total_stack[:, :, 12]\n",
        "    sentinel2[:, :, 11] = total_stack[:, :, 7]\n",
        "    sentinel2[:, :, 12] = total_stack[:, :, 8]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSAwf7WVuhN2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_P1HyB9I3Y8"
      },
      "source": [
        "sliding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfdgOtpfI-TY"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncaoujg8H-7h"
      },
      "source": [
        "# **1. Load the EuroSAT benchmark dataset as input data**\n",
        "The `EuroSAT benchmark dataset` is `drive/MyDrive/Land Classificatiion/S2_Tile_based_classification/01_Input_data/S2_tile_4_training/`. This folder contains a folder for each of the ten land cover classes. The first step involves loading all the EuroSAT images from all the folders as a `numpy` array. You can use the function `.LoadFile` from the GDAL Python bindings module `gdal_array` to read a raster image (e.g. in `.tif` format) into a `numpy.array`.\n",
        "\n",
        "The result is `lst_arr_training`, a list of 10,000 arrays and each array has the dimension `[13, 64, 64]`. For each of the images we want to create a `numpy.array` with ten entries indicating in binary form (0 or 1) the class the image belongs to. The resulting list is called `lst_gt_training` and has the same length as the list of training images.\n",
        "\n",
        "**NOTE**: for training purposes, the example only makes use of a subset of 10,000 images of the EuroSAT benchmark dataset(27,000 images).\n",
        "\n",
        "\n",
        "Define the folder where the EuroSAT training images are located."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlvPBWKQhQD"
      },
      "source": [
        "# MAIN_PATH = 'drive/MyDrive/Land Classification/S2_Tile_based_classification/'\n",
        "DATA_PATH = 'drive/MyDrive/Land Classification/S2_Tile_based_classification/01_Input_data/S2_tile_4_training/'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5F7sVtqRBWN"
      },
      "source": [
        "Loop over the training data folders and build up two lists:\n",
        "\n",
        "* `lst_arr_training` - List of training arrays\n",
        "* `lst_gt_training` _ List of arrays indicating to which class each image belongs to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPzhHYgYRjp0",
        "outputId": "e09d09c8-805e-497b-f5b3-236a07053324"
      },
      "source": [
        "import glob\n",
        "len_data_for_training_tmp = 1000\n",
        "# folder_for_training = glob.glob(MAIN_PATH+DATA_PATH+'*/')\n",
        "folder_for_training = glob.glob(DATA_PATH+'*/')\n",
        "\n",
        "print('[AI4EO_MOOC]_log: There are %d folders' % (len(folder_for_training)))\n",
        "\n",
        "lst_arr_training=[]\n",
        "lst_gt_training = []\n",
        "for i in range(0,len(folder_for_training)):\n",
        "  data_for_training_tmp=glob.glob(folder_for_training[i]+'*.tif')\n",
        "\n",
        "  print('[AI4EO_MOOC]_log: There are %d images for %s class' % (\n",
        "      \n",
        "      len_data_for_training_tmp, folder_for_training[i][40:-1])\n",
        "      )\n",
        "  \n",
        "  for j in range(0, len_data_for_training_tmp):\n",
        "      arr_tmp = gdal_array.LoadFile(data_for_training_tmp[j])\n",
        "      lst_arr_training.append(arr_tmp)\n",
        "      tmp_gt = np.zeros(10)\n",
        "      tmp_gt[i]=1\n",
        "      lst_gt_training.append(tmp_gt)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: There are 10 folders\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/River class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/SeaLake class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/AnnualCrop class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Forest class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/HerbaceousVegetation class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Highway class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Industrial class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Pasture class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/PermanentCrop class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Residential class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTGiHQLMUg-q",
        "outputId": "959e16d7-e77b-4a11-c748-8bafaa4dc82b"
      },
      "source": [
        "type(lst_gt_training[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5lcmavLjt1U"
      },
      "source": [
        "Let us inspect the length of the created lists as well as the dimensions of the images. Both lists have a length of 10,000 items and each image have the following dimension[13, 64,64]. The binary class vector has a length of 10, representing the 10 land cover classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-DPXIFwcHND",
        "outputId": "144891f9-c3ad-42cb-a332-25fc5cc9b243"
      },
      "source": [
        "print(len(lst_arr_training), len(lst_gt_training))\n",
        "print(lst_arr_training[1000-1].shape, lst_gt_training[1000-1].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 10000\n",
            "(13, 64, 64) (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COULy5n1kovI"
      },
      "source": [
        "Next, we'll transform the two lists of arrays into multistack arrays. This can be done with the numPy function `.asarray()`. The result is two numpy arrays with the following specifications:   \n",
        "* `arr_training`: 4 dimensions (10000, 13, 64, 64)-->(number of images, bands, rows, columns)\n",
        "* `arr_gt`: 2 dimensions (10000, 10)--> (number of images, columns)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqN3NZlCkkje",
        "outputId": "313f9df2-82fc-4a5a-e8df-0f1a0420a28a"
      },
      "source": [
        "arr_training = np.asarray(lst_arr_training)\n",
        "arr_gt = np.asarray(lst_gt_training)\n",
        "\n",
        "arr_training.shape, arr_gt.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 13, 64, 64), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhaCTdEjl-TV"
      },
      "source": [
        "##**Reshape the multi-array's native shape to an AI readable shape**\n",
        "\n",
        "We have to reshape the array with the training images from its native shape(10000, 13,64,64) to a shape that is readable by Artificial Intelligence algorithms. For this reason, the multi-dimension array `arr_training` needs to be re-organised into the following dimensions:   \n",
        "* `arr_training_res`: 4 dimensions(10000,64,64,13)-->(number of images, rows, columns, bands)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpxHfBGzl1f7",
        "outputId": "89b3b47a-d5be-45f2-8985-48d07c7adc93"
      },
      "source": [
        "num_of_img,bands,rows,columns=arr_training.shape\n",
        "print('[AI4EO_MOOC]_log: Reshape array from native shape (num_of_img:%d, bands:%d, rows:%d, columns:%d) to AI readable shape (num_of_img:%d, rows:%d, columns:%d, bands:%d)...' % (num_of_img,bands,rows,columns, num_of_img,rows,columns,bands))\n",
        "\n",
        "arr_training_res = np.reshape(arr_training,(num_of_img,rows,columns,bands))\n",
        "arr_training_res.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Reshape array from native shape (num_of_img:10000, bands:13, rows:64, columns:64) to AI readable shape (num_of_img:10000, rows:64, columns:64, bands:13)...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 64, 64, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElXLe1k7oLH8",
        "outputId": "3c795ba3-d7e9-4f57-9408-a2954b7a83dd"
      },
      "source": [
        "type(arr_training_res)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD44WxPToUOo"
      },
      "source": [
        "##**Normalisation of the image radiances to a [0,1] interval**\n",
        "\n",
        "As a final step, we normalize thedata and bring the data into a [0,1] range. We want to transform the data type from `uint16 - [0,65535]` to `float32`. Then we loop over each image in the numpy multi-dimensional array, we retreive the maximum value of each image with the numpy function `.amax()` and then we divide each value in the array by the maximum value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISTo5OOHoSrV",
        "outputId": "a7518695-e70d-435a-9d2f-c7516157ce26"
      },
      "source": [
        "print('[AI4EO_MOOC]_log: Normalization of data into [0,1] interval...')\n",
        "arr_training_res = arr_training_res.astype('float32')\n",
        "for i in range(0, len(arr_training_res)):\n",
        "  amax_tmp=np.amax(arr_training_res[i,:,:,:])\n",
        "  arr_training_res[i,:,:,:] = arr_training_res[i,:,:,:] / amax_tmp"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Normalization of data into [0,1] interval...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WMbr-UNQZC4"
      },
      "source": [
        "Let us inspect one image from the array. Notice that the interval range is now a float number between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8k6cHerOvVz",
        "outputId": "299878ea-d8ee-4176-e70a-cb3525ec64a4"
      },
      "source": [
        "arr_training_res[1000-1,:,:,:]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.3875834 , 0.3875834 , 0.3875834 , ..., 0.38874385,\n",
              "         0.38903394, 0.38932404],\n",
              "        [0.38961416, 0.3901944 , 0.39048448, ..., 0.39657673,\n",
              "         0.39773718, 0.3988976 ],\n",
              "        [0.40034813, 0.40179867, 0.4032492 , ..., 0.41746446,\n",
              "         0.4192051 , 0.42094576],\n",
              "        ...,\n",
              "        [0.3948361 , 0.3948361 , 0.3948361 , ..., 0.39454597,\n",
              "         0.39454597, 0.39454597],\n",
              "        [0.3948361 , 0.3948361 , 0.3951262 , ..., 0.40382943,\n",
              "         0.40557006, 0.40760082],\n",
              "        [0.40934145, 0.4113722 , 0.41340294, ..., 0.42181608,\n",
              "         0.42210618, 0.42239627]],\n",
              "\n",
              "       [[0.3872933 , 0.3872933 , 0.3875834 , ..., 0.3913548 ,\n",
              "         0.3916449 , 0.39193502],\n",
              "        [0.39251524, 0.39280534, 0.39338556, ..., 0.39628664,\n",
              "         0.39657673, 0.39657673],\n",
              "        [0.39657673, 0.39657673, 0.39657673, ..., 0.3959965 ,\n",
              "         0.3959965 , 0.3959965 ],\n",
              "        ...,\n",
              "        [0.4029591 , 0.4029591 , 0.4029591 , ..., 0.4029591 ,\n",
              "         0.4029591 , 0.4029591 ],\n",
              "        [0.4029591 , 0.4029591 , 0.4029591 , ..., 0.4029591 ,\n",
              "         0.4029591 , 0.4032492 ],\n",
              "        [0.4032492 , 0.4032492 , 0.4035393 , ..., 0.4029591 ,\n",
              "         0.40266898, 0.4023789 ]],\n",
              "\n",
              "       [[0.40382943, 0.40382943, 0.40382943, ..., 0.4032492 ,\n",
              "         0.4032492 , 0.4032492 ],\n",
              "        [0.4032492 , 0.4032492 , 0.4035393 , ..., 0.4032492 ,\n",
              "         0.4032492 , 0.4029591 ],\n",
              "        [0.4029591 , 0.40266898, 0.40266898, ..., 0.4029591 ,\n",
              "         0.4029591 , 0.4029591 ],\n",
              "        ...,\n",
              "        [0.40527996, 0.40586016, 0.4067305 , ..., 0.41398317,\n",
              "         0.41485348, 0.41572383],\n",
              "        [0.41630402, 0.41688424, 0.41717437, ..., 0.41862488,\n",
              "         0.41862488, 0.41862488],\n",
              "        [0.41862488, 0.41862488, 0.41833478, ..., 0.41311285,\n",
              "         0.41224253, 0.4116623 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.14070205, 0.14070205, 0.13606034, ..., 0.12880766,\n",
              "         0.12822744, 0.12706701],\n",
              "        [0.12561648, 0.12445605, 0.12329562, ..., 0.11981433,\n",
              "         0.11923411, 0.11807369],\n",
              "        [0.11749347, 0.11720336, 0.11633305, ..., 0.11691326,\n",
              "         0.11691326, 0.11662315],\n",
              "        ...,\n",
              "        [0.11430229, 0.11488251, 0.11604293, ..., 0.11575283,\n",
              "         0.11430229, 0.11546272],\n",
              "        [0.11807369, 0.12271541, 0.1302582 , ..., 0.29503918,\n",
              "         0.32695097, 0.35567158],\n",
              "        [0.3794604 , 0.3994778 , 0.41746446, ..., 0.5256745 ,\n",
              "         0.53495795, 0.537859  ]],\n",
              "\n",
              "       [[0.12097476, 0.12097476, 0.12039454, ..., 0.11720336,\n",
              "         0.11575283, 0.11517262],\n",
              "        [0.11575283, 0.11662315, 0.11691326, ..., 0.11604293,\n",
              "         0.11488251, 0.11430229],\n",
              "        [0.1145924 , 0.11546272, 0.11546272, ..., 0.12039454,\n",
              "         0.12416594, 0.13170873],\n",
              "        ...,\n",
              "        [0.48709023, 0.56367856, 0.62257034, ..., 0.5619379 ,\n",
              "         0.5822454 , 0.608065  ],\n",
              "        [0.63359445, 0.65564257, 0.6733391 , ..., 0.6005222 ,\n",
              "         0.5921091 , 0.58775747],\n",
              "        [0.58775747, 0.5894981 , 0.5915289 , ..., 0.58369595,\n",
              "         0.60255295, 0.6231506 ]],\n",
              "\n",
              "       [[0.12068465, 0.12068465, 0.11749347, ..., 0.11517262,\n",
              "         0.11488251, 0.1145924 ],\n",
              "        [0.1145924 , 0.11604293, 0.1183638 , ..., 0.41746446,\n",
              "         0.49927473, 0.5677401 ],\n",
              "        [0.61473745, 0.63881636, 0.64606905, ..., 0.62257034,\n",
              "         0.65129095, 0.6715985 ],\n",
              "        ...,\n",
              "        [0.6301131 , 0.589208  , 0.57122135, ..., 0.6425878 ,\n",
              "         0.6370757 , 0.63388455],\n",
              "        [0.64868003, 0.68523353, 0.7365825 , ..., 0.7856107 ,\n",
              "         0.76211196, 0.75776035],\n",
              "        [0.77429646, 0.8018567 , 0.8236147 , ..., 0.55149406,\n",
              "         0.60226285, 0.65361184]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0gubL7dRDfz"
      },
      "source": [
        "# **2. Create training and test subsets from input data**\n",
        "\n",
        "We'll randomly split the training data into a `training subset` and a `testing subset`. Scikit-learn offers a popular function called `train-test-split()`, which creates 4 subsets based on the input and output variables `X - arr_training_res` and `y - arr_gt`. The function takes the following kwargs.\n",
        "* `arrays`: input and output data arrays\n",
        "* `test_size`: a float number representing the proportion of the input dataset to include in the test subset\n",
        "* `random_state`: An integer assuring reproducibility of the random shuffling of the data\n",
        "\n",
        "We'll use 85% of the input data for training and 15% for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB7vhItcQw02",
        "outputId": "741f9de4-dce5-458c-8ddf-04fa1f51e1ee"
      },
      "source": [
        "test_size=0.15\n",
        "print('[AI4EO_MOOC]_log: Training (%0.2f %%) and validation (%0.2f %%) split..' % (\n",
        "      (1-test_size)*100,(test_size)*100))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        arr_training_res,\n",
        "        arr_gt,\n",
        "        test_size=test_size,\n",
        "        random_state=42)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Training (85.00 %) and validation (15.00 %) split..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjczIXyaTzuQ"
      },
      "source": [
        "# **3. Define the Convolutional Neural Network architecture**\n",
        "\n",
        "As our first step, we'll initiate a `sequential neural network` model with the Keras class `keras.Sequential()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4MBqhs0ULzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e62f42-8fc5-424b-d6a0-42b15c602861"
      },
      "source": [
        "_, num_classes = y_train.shape\n",
        "print('[AI4EO_MOOC]_log: Convolutional Neural Network architecture:')\n",
        "model = keras.Sequential()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Convolutional Neural Network architecture:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQnyt479iNG8"
      },
      "source": [
        "The next step is to build up the architecture of the `Convolution Neural Network (CNN)`, with the function `model.add()`. A `CNN` composes of the following set of layers:\n",
        "\n",
        "* `Conv2D`: Convolutional layer with number of filters, e.g. 32 or 64, the shape of thje filter ((3,3), (5,5),...) and the application of padding\n",
        "* `Activation`: Activation layer, e.g. `relu`, `sigmoid`, ...\n",
        "* `Maxpooling2D`: Max Pooling layer with shape (2,2), (3,3), ...\n",
        "* `Dropout`: to reduce overfitting\n",
        "\n",
        "In the following code block, we build three blocks of layers:\n",
        "\n",
        "* **First block of layers**\n",
        "The first block of layers consist of two `Conv2D` layers with 32 neurons and we add non-linear properties by adding an `Activation` layer in between. We then define a `MaxPooling2D` layer, which downsamples the input by taking the maximum value of a given window size. The block of layers finishes with `Dropout` layer, which randomly skips 25% of the interconnections.\n",
        "\n",
        "* **Second block of layers**\n",
        "The second block of layers consists of two `Conv2D` layers, but with 64 neurons and we add non-linear properties by adding an `Activation` layer in between. We then define a `MaxPooling2D` layer, which downsamples the input by taking the maximum value of a given window size. The block of layers finishes with a  `Dropout` layer, which randomly skips 25% of the interconnections.\n",
        "\n",
        "* **Third block of layers**\n",
        "The third block consists of two `Dense` layers, which are fully-connected layers. In between, we again add non-linear properties by adding an `Activation` layer. The number of neurons of the final 'Dense` layer has to be the same as the number of land use classes, in this case 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNZhkwRLmPI8"
      },
      "source": [
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGAFthPApDpK"
      },
      "source": [
        "After the model architecture has been defined you can compile(configure) the model with `model.compile()` and define the following hyperparameters:\n",
        "\n",
        "* `loss='categorical_crossentropy'`- Categorical crossentropy is one of many loss options and calculates the crossentropy loss between the labels and the predictions\n",
        "* `optimizer=RMSprop(lr=0.0001, decay=1e-6)`- Optimizers are algorithms the network learns from\n",
        "* `metrics=['accuracy']`- is used to evaluate how the model is performing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLS4oUxNn0Yy"
      },
      "source": [
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSWECAheqqgv"
      },
      "source": [
        ""
      ]
    }
  ]
}