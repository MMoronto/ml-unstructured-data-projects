{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tile-based classification using Sentinel-2 and EuroSAT data-Training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Nb6axbd2makj-lAkYy_81CqLwf8aKOQ9",
      "authorship_tag": "ABX9TyMy7OhAxjtyYMt7wdq+ivIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoronto/ml-unstructured-data-projects/blob/master/Tile_based_classification_using_Sentinel_2_and_EuroSAT_data_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeFaI7puszgm"
      },
      "source": [
        "##**Intro**\n",
        "\n",
        "This workflow explores the process of training a `Convolutional Neural Network (CNN)` with Keras based on the benchmark dataset EuroSAT. This noote book contains notes I've taken as I work through the example workflow presented in the AI for Earth monitoring MOOC on Futurelearn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkSeuefswyfX"
      },
      "source": [
        "##**Machine-Learning Algorithm**\n",
        "\n",
        "This example develops a `Sequential Convolutional Neural Network (CNN)` with TF Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyS5FFHUxcN_"
      },
      "source": [
        "##**Data**\n",
        "The model is trained on the EuroSAT benchmark dataset which is based on Sentinel-2 satellite images and consists of 27,000 labeled and geo-referenced images.The dataset provides information on the following ten land cover/land use cases:\n",
        "* `Annual Crop`\n",
        "* `Forest`\n",
        "* `Herbaceous Vegetation`\n",
        "* `Highway`\n",
        "* Industrial`\n",
        "* `Pasture`\n",
        "* `Permanent Crop`\n",
        "* `Residential`\n",
        "* `River`\n",
        "* `Sea Lake`\n",
        "\n",
        "The benchmark dataset can be used to detect `land cover / land use changes`. The geo-referenced datasset EuroSAT is publicly accessible here: https://github.com/phelber/eurosat\n",
        "\n",
        "## Notebook Outline\n",
        "* 1 - Load the EuroSAT benchmark dataset as input data\n",
        "* 2 - Create training and test subsets from input data\n",
        "* 3 - Define the Convolutional Neural Network architecture\n",
        "* 4 - Fit (train) the convolutional neural network (CNN)\n",
        "* 5 - Evaluate the performance of the CNN model with a confusion matrix\n",
        "\n",
        "\n",
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsppuKATLSor"
      },
      "source": [
        "## Begin S3FS Import Snippet ##\n",
        "import os, sys\n",
        "s3_home = os.getcwd()\n",
        "try: sys.path.remove(s3_home) # Remove the S3 from the $path\n",
        "except Exception: pass\n",
        "\n",
        "# current_dir = os.getcwd()\n",
        "\n",
        "# os.chdir('/home/jovyan') # Temporarily move to another directory\n",
        "\n",
        "# Begin imports #\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from osgeo import gdal_array\n",
        "from matplotlib import pyplot as pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "# end imports #\n",
        "\n",
        "# os.chdir(current_dir) # go back to your previous dir\n",
        "\n",
        "# sys.path.append(s3_home) # restore the s3 root in the $path\n",
        "\n",
        "## end s3fs import snippet ##\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttI_pu8vzd8_"
      },
      "source": [
        "# !unzip \"drive/MyDrive/Land Classification/S2_Tile_based_classification.zip\" -d \"drive/MyDrive/Land Classification/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-DF0lwEWyWk"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3mvsK6CKOO-"
      },
      "source": [
        "from_folder_to_stack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwNtHfldXIaf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "'''\n",
        "function name:\n",
        "  from_folder_to_stack\n",
        "description:\n",
        "  This function transforms the .SAFE file into three different arrays (10m, 20m and 60m).\n",
        "Input:\n",
        "  safe_path: the path of the .SAFE file;\n",
        "  data_bands_20m: if True, the fumnction computes stack using Sentinel2 band with 20m of pixel resolution (default=True);\n",
        "  data_bands_60m: if True, the function computes stack using Sentinel2 band with 60m of pixel resolution (default=True);\n",
        "Output:\n",
        "  stack_10m: stack with the following S2L1C bands (B02, B03, B04, B08)\n",
        "  stack_20m: stack with the following S2L1C bands (B05, B06, B07, B11, B12, B8A)\n",
        "  stack_60m: stack with the following S2L1C bands (B01, mB09, B10)\n",
        "'''\n",
        "def from_folder_to_stack(\n",
        "    safe_path,\n",
        "    data_bands_20m=True,\n",
        "    data_bands_60m=True,\n",
        "    ):\n",
        "\n",
        "  level_folder_name_list = glob.glob(safe_path + 'GRANULE/*')\n",
        "  level_folder_name = level_folder_name_list[0]\n",
        "\n",
        "  if level_folder_name.find(\"L2A\") < 0:\n",
        "    safe_path = [level_folder_name + '/IMG_DATA/']\n",
        "  else:\n",
        "    safe_path_10m = level_folder_name + '/IMG_DATA/R10m/'\n",
        "    safe_path = [safe_path_10m]\n",
        "\n",
        "  text_files = []\n",
        "\n",
        "  for i in range(0, len(safe_path)):\n",
        "      print(\"[AI4EO_MOOC]_log: Loading .jp2 images in %s\" % (safe_path[i]))\n",
        "      text_files_tmp = [f for f in os.listdir(safe_path[i]) if f.endswith('.jp2')]\n",
        "      text_files.append(text_files_tmp)\n",
        "\n",
        "  lst_stack_60m=[]\n",
        "  lst_code_60m=[]\n",
        "  lst_stack_20m=[]\n",
        "  lst_code_20m=[]\n",
        "  lst_stack_10m=[]\n",
        "  lst_code_10m=[]\n",
        "  for i in range(0, len(safe_path)):\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Reading .jp2 files in %s\" % (safe_path[i]))\n",
        "    for name in range(0, len(text_files[i])):\n",
        "      text_files_tmp = text_files[i]\n",
        "      if data_bands_60m == True:\n",
        "        cond_60m = ( (text_files_tmp[name].find(\"B01\") > 0) or (text_files_tmp[name].find(\"B09\") > 0)\n",
        "                    or (text_files_tmp[name].find(\"B10\") > 0))\n",
        "        if cond_60m:\n",
        "            print(\"[AI4EO_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "            lst_stack_60m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "            lst_code_60m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "      if data_bands_20m == True:\n",
        "          cond_20m = (text_files_tmp[name].find(\"B05\") > 0) or (text_files_tmp[name].find(\"B06\") > 0) or (\n",
        "                      text_files_tmp[name].find(\"B07\") > 0) or (text_files_tmp[name].find(\"B11\") > 0) or (\n",
        "                                  text_files_tmp[name].find(\"B12\") > 0) or (text_files_tmp[name].find(\"B8A\") > 0)\n",
        "          cond_60m_L2 = (text_files_tmp[name].find(\"B05_60m\") < 0) and (text_files_tmp[name].find(\"B06_60m\") < 0) and (\n",
        "                      text_files_tmp[name].find(\"B07_60m\") < 0) and (text_files_tmp[name].find(\"B11_60m\") < 0) and (\n",
        "                                  text_files_tmp[name].find(\"B12_60m\") < 0) and (text_files_tmp[name].find(\"B8A_60m\") < 0)\n",
        "          cond_20m_tot = cond_20m and cond_60m_L2\n",
        "          if cond_20m_tot:\n",
        "              print(\"[AI4E_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "              lst_stack_20m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "              lst_code_20m.append(text_files_tmp[name][24:26])\n",
        "      else:\n",
        "        stack_20m = 0\n",
        "\n",
        "      cond_10m = (text_files_tmp[name].find(\"B02\") > 0) or (text_files_tmp[name].find(\"B03\") > 0) or (\n",
        "                  text_files_tmp[name].find(\"B04\") > 0) or (text_files_tmp[name].find(\"B08\") > 0)\n",
        "      cond_20m_L2 = (text_files_tmp[name].find(\"B02_20m\") < 0) and (text_files_tmp[name].find(\"B03_20m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_20m\") < 0) and (text_files_tmp[name].find(\"B08_20m\") < 0)\n",
        "      cond_60m_L2 = (text_files_tmp[name].find(\"B02_60m\") < 0) and (text_files_tmp[name].find(\"B03_60m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_60m\") < 0) and (text_files_tmp[name].find(\"B08_60m\") < 0)\n",
        "      cond_10m_tot = cond_10m and cond_20m_L2 and cond_60m_L2\n",
        "\n",
        "      if cond_10m_tot:\n",
        "          print(\"[AI4E)_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "          lst_stack_10m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "          lst_code_10m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "\n",
        "  stack_10m=np.asarray(lst_stack_10m)\n",
        "  sorted_list_10m = ['02', '03', '04', '08']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 10m...')\n",
        "  stack_10m_final_sorted = stack_sort(stack_10m, lst_code_10m, sorted_list_10m)\n",
        "\n",
        "  stack_20m=np.asarray(lst_stack_20m)\n",
        "  sorted_list_20m = ['05', '06', '07', '11', '12', '8A']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 20m...')\n",
        "  stack_20m_final_sorted = stack_sort(stack_20m, lst_code_20m, sorted_list_20m)\n",
        "              \n",
        "  stack_60m=np.asarray(lst_stack_60m)\n",
        "  sorted_list_60m = ['01', '09', '10']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 60m...')\n",
        "  stack_60m_final_sorted = stack_sort(stack_60m, lst_code_60m, sorted_list_60m)\n",
        "\n",
        "  return stack_10m_final_sorted, stack_20m_final_sorted, stack_60m_final_sorted"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwSv2ExkGK9e"
      },
      "source": [
        "stack_sort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW6E0LvU_wB0"
      },
      "source": [
        "def stack_sort(stack_in, lst_code, sorted_list):\n",
        "  b, r, c = stack_in.shape\n",
        "  stack_sorted = np.zeros((r,c,b), dtype=np.unit16)\n",
        "\n",
        "  len_list_bands = len(lst_code)\n",
        "\n",
        "  c = np.zeros((len_list_bands), dtype=np.unit8)\n",
        "  count = 0\n",
        "  count_sort = 0\n",
        "  while count_sort != len_list_bands:\n",
        "    if lst_code[count] == sorted_list[count_sort]:\n",
        "      c[count_sort] = count\n",
        "      count_sort = count_sort + 1\n",
        "      count = 0\n",
        "    else:\n",
        "      count = count + 1\n",
        "    print('[AI4EO_MOOC]_log: sorted list:', sorted_list)\n",
        "    print('[AI4EO_MOOC]_log: bands:', c)\n",
        "    for i in range(0, len_list_bands):\n",
        "        stack_sorted[:,:,i]=stack_in[c[i],:,:]\n",
        "    \n",
        "    return stack_sorted"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYkZZV_IrQs"
      },
      "source": [
        "resample_3d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS-jKoKI8uK"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  resample_3d\n",
        "description:\n",
        "  wrapper of ndimage zoom. Bilinear interpolation for resampling array\n",
        "input:\n",
        "  stack: array to be resampled;\n",
        "  row10m: the expected row;\n",
        "  col10m: the expected col;\n",
        "  rate: the rate of the transformation;\n",
        "output:\n",
        "  stack_10m: resampled array\n",
        "'''\n",
        "def resample_3d(\n",
        "        stack,\n",
        "        row10m,\n",
        "        col10m,\n",
        "        rate):\n",
        "    row, col, bands = stack.shape\n",
        "    print(\"[AI4EO_MOOC]_log: Array shape (%d,%d,%d)\" % (row, col, bands))\n",
        "\n",
        "    stack_10m = np.zeros((row10m, col10m, bands),dtype=np.uint16)\n",
        "    print(\"[AI4EO_MOOC]_log: Resize array bands from (%d,%d,%d) to (%d,%d,%d)\" % (\n",
        "        row, col, bands, row10m, col10m, bands))\n",
        "    \n",
        "    for i in range(0, bands):\n",
        "      stack_10m[:, :, i] = ndimage.zoom(stack[:, :,i], rate)\n",
        "\n",
        "    del (stack)\n",
        "\n",
        "    return stack_10m"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0Kp7sWIwPk"
      },
      "source": [
        "sentinel2_format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3mAuYCJAO-"
      },
      "source": [
        "'''\n",
        "function name:\n",
        "  sentinel2_format\n",
        "description:\n",
        "  This function transforms the multistack into sentinel2 format arrays with bands in the right positions for our AI model.\n",
        "input:\n",
        "  total_stack: array that is the concatenation of stack10, stack_20mTo10m and stack_60mTo10m.\n",
        "output:\n",
        "  sentinel2: sentinel2 format array\n",
        "'''\n",
        "def sentinel2_format(\n",
        "        total_stack):\n",
        "  \n",
        "    row_tot, col_tot, bands_tot = total_stack.shape\n",
        "    sentinel2 = np.zeros((row_tot, col_tot, bands_tot),dtype=np.unit16)\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Creating a total stack with following list of bands:\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 1 - Coastal aerosol\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 2 - Blue\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 3 - Green\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 4 - Red\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 5 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 6 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 7 - Vegetation red edge\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8 - NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 8A - Narrow NIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 9 - Water vapour\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 10 - SWIR - Cirrus\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 11 - SWIR\")\n",
        "    print(\"[AI4EO_MOOC]_log: Band 12 - SWIR\")\n",
        "\n",
        "    sentinel2[:, :, 0] = total_stack[:, :, 10]\n",
        "    sentinel2[:, :, 1] = total_stack[:, :, 0]\n",
        "    sentinel2[:, :, 2] = total_stack[:, :, 1]\n",
        "    sentinel2[:, :, 3] = total_stack[:, :, 2]\n",
        "    sentinel2[:, :, 4] = total_stack[:, :, 4]\n",
        "    sentinel2[:, :, 5] = total_stack[:, :, 5]\n",
        "    sentinel2[:, :, 6] = total_stack[:, :, 6]\n",
        "    sentinel2[:, :, 7] = total_stack[:, :, 3]\n",
        "    sentinel2[:, :, 8] = total_stack[:, :, 9]\n",
        "    sentinel2[:, :, 9] = total_stack[:, :, 11]\n",
        "    sentinel2[:, :, 10] = total_stack[:, :, 12]\n",
        "    sentinel2[:, :, 11] = total_stack[:, :, 7]\n",
        "    sentinel2[:, :, 12] = total_stack[:, :, 8]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_P1HyB9I3Y8"
      },
      "source": [
        "sliding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfdgOtpfI-TY"
      },
      "source": [
        "'''\n",
        "Function_name:\n",
        "  sliding\n",
        "description:\n",
        "input:\n",
        "  shape: the target shape\n",
        "  window_size: the shape of the window\n",
        "  step-size:\n",
        "  fixed\n",
        "output:\n",
        "  windows:\n",
        "'''\n",
        "\n",
        "def sliding(shape, window_size, step_size=None, fixed=True):\n",
        "    h, w = shape\n",
        "    if step_size:\n",
        "        h_step = step_size\n",
        "        w_step = step_size\n",
        "    else:\n",
        "        h_step = window_size\n",
        "        w_step = window_size\n",
        "\n",
        "    h_wind = window_size\n",
        "    w_wind = window_size\n",
        "    windows = []\n",
        "    for y in range(0, h, h_step):\n",
        "        for x in range(0, w, w_step):\n",
        "            h_min = min(h_wind, h - y)\n",
        "            w_min = min(w_wind, w - x)\n",
        "            if fixed:\n",
        "              if h_min < h_wind or w_min < w_wind:\n",
        "                  continue\n",
        "            window = (x, y, w_min, h_min)\n",
        "            windows.append(window)\n",
        "\n",
        "    return windows"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncaoujg8H-7h"
      },
      "source": [
        "# **1. Load the EuroSAT benchmark dataset as input data**\n",
        "The `EuroSAT benchmark dataset` is `drive/MyDrive/Land Classificatiion/S2_Tile_based_classification/01_Input_data/S2_tile_4_training/`. This folder contains a folder for each of the ten land cover classes. The first step involves loading all the EuroSAT images from all the folders as a `numpy` array. You can use the function `.LoadFile` from the GDAL Python bindings module `gdal_array` to read a raster image (e.g. in `.tif` format) into a `numpy.array`.\n",
        "\n",
        "The result is `lst_arr_training`, a list of 10,000 arrays and each array has the dimension `[13, 64, 64]`. For each of the images we want to create a `numpy.array` with ten entries indicating in binary form (0 or 1) the class the image belongs to. The resulting list is called `lst_gt_training` and has the same length as the list of training images.\n",
        "\n",
        "**NOTE**: for training purposes, the example only makes use of a subset of 10,000 images of the EuroSAT benchmark dataset(27,000 images).\n",
        "\n",
        "\n",
        "Define the folder where the EuroSAT training images are located."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlvPBWKQhQD"
      },
      "source": [
        "# MAIN_PATH = 'drive/MyDrive/Land Classification/S2_Tile_based_classification/'\n",
        "DATA_PATH = 'drive/MyDrive/Land Classification/S2_Tile_based_classification/01_Input_data/S2_tile_4_training/'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5F7sVtqRBWN"
      },
      "source": [
        "Loop over the training data folders and build up two lists:\n",
        "\n",
        "* `lst_arr_training` - List of training arrays\n",
        "* `lst_gt_training` _ List of arrays indicating to which class each image belongs to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPzhHYgYRjp0",
        "outputId": "e09d09c8-805e-497b-f5b3-236a07053324"
      },
      "source": [
        "import glob\n",
        "len_data_for_training_tmp = 1000\n",
        "# folder_for_training = glob.glob(MAIN_PATH+DATA_PATH+'*/')\n",
        "folder_for_training = glob.glob(DATA_PATH+'*/')\n",
        "\n",
        "print('[AI4EO_MOOC]_log: There are %d folders' % (len(folder_for_training)))\n",
        "\n",
        "lst_arr_training=[]\n",
        "lst_gt_training = []\n",
        "for i in range(0,len(folder_for_training)):\n",
        "  data_for_training_tmp=glob.glob(folder_for_training[i]+'*.tif')\n",
        "\n",
        "  print('[AI4EO_MOOC]_log: There are %d images for %s class' % (\n",
        "      \n",
        "      len_data_for_training_tmp, folder_for_training[i][40:-1])\n",
        "      )\n",
        "  \n",
        "  for j in range(0, len_data_for_training_tmp):\n",
        "      arr_tmp = gdal_array.LoadFile(data_for_training_tmp[j])\n",
        "      lst_arr_training.append(arr_tmp)\n",
        "      tmp_gt = np.zeros(10)\n",
        "      tmp_gt[i]=1\n",
        "      lst_gt_training.append(tmp_gt)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: There are 10 folders\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/River class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/SeaLake class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/AnnualCrop class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Forest class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/HerbaceousVegetation class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Highway class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Industrial class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Pasture class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/PermanentCrop class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Residential class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTGiHQLMUg-q",
        "outputId": "959e16d7-e77b-4a11-c748-8bafaa4dc82b"
      },
      "source": [
        "type(lst_gt_training[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5lcmavLjt1U"
      },
      "source": [
        "Let us inspect the length of the created lists as well as the dimensions of the images. Both lists have a length of 10,000 items and each image have the following dimension[13, 64,64]. The binary class vector has a length of 10, representing the 10 land cover classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-DPXIFwcHND",
        "outputId": "144891f9-c3ad-42cb-a332-25fc5cc9b243"
      },
      "source": [
        "print(len(lst_arr_training), len(lst_gt_training))\n",
        "print(lst_arr_training[1000-1].shape, lst_gt_training[1000-1].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000 10000\n",
            "(13, 64, 64) (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COULy5n1kovI"
      },
      "source": [
        "Next, we'll transform the two lists of arrays into multistack arrays. This can be done with the numPy function `.asarray()`. The result is two numpy arrays with the following specifications:   \n",
        "* `arr_training`: 4 dimensions (10000, 13, 64, 64)-->(number of images, bands, rows, columns)\n",
        "* `arr_gt`: 2 dimensions (10000, 10)--> (number of images, columns)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqN3NZlCkkje",
        "outputId": "313f9df2-82fc-4a5a-e8df-0f1a0420a28a"
      },
      "source": [
        "arr_training = np.asarray(lst_arr_training)\n",
        "arr_gt = np.asarray(lst_gt_training)\n",
        "\n",
        "arr_training.shape, arr_gt.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 13, 64, 64), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhaCTdEjl-TV"
      },
      "source": [
        "##**Reshape the multi-array's native shape to an AI readable shape**\n",
        "\n",
        "We have to reshape the array with the training images from its native shape(10000, 13,64,64) to a shape that is readable by Artificial Intelligence algorithms. For this reason, the multi-dimension array `arr_training` needs to be re-organised into the following dimensions:   \n",
        "* `arr_training_res`: 4 dimensions(10000,64,64,13)-->(number of images, rows, columns, bands)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpxHfBGzl1f7",
        "outputId": "89b3b47a-d5be-45f2-8985-48d07c7adc93"
      },
      "source": [
        "num_of_img,bands,rows,columns=arr_training.shape\n",
        "print('[AI4EO_MOOC]_log: Reshape array from native shape (num_of_img:%d, bands:%d, rows:%d, columns:%d) to AI readable shape (num_of_img:%d, rows:%d, columns:%d, bands:%d)...' % (num_of_img,bands,rows,columns, num_of_img,rows,columns,bands))\n",
        "\n",
        "arr_training_res = np.reshape(arr_training,(num_of_img,rows,columns,bands))\n",
        "arr_training_res.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Reshape array from native shape (num_of_img:10000, bands:13, rows:64, columns:64) to AI readable shape (num_of_img:10000, rows:64, columns:64, bands:13)...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 64, 64, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElXLe1k7oLH8",
        "outputId": "3c795ba3-d7e9-4f57-9408-a2954b7a83dd"
      },
      "source": [
        "type(arr_training_res)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD44WxPToUOo"
      },
      "source": [
        "##**Normalisation of the image radiances to a [0,1] interval**\n",
        "\n",
        "As a final step, we normalize thedata and bring the data into a [0,1] range. We want to transform the data type from `uint16 - [0,65535]` to `float32`. Then we loop over each image in the numpy multi-dimensional array, we retreive the maximum value of each image with the numpy function `.amax()` and then we divide each value in the array by the maximum value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISTo5OOHoSrV",
        "outputId": "a7518695-e70d-435a-9d2f-c7516157ce26"
      },
      "source": [
        "print('[AI4EO_MOOC]_log: Normalization of data into [0,1] interval...')\n",
        "arr_training_res = arr_training_res.astype('float32')\n",
        "for i in range(0, len(arr_training_res)):\n",
        "  amax_tmp=np.amax(arr_training_res[i,:,:,:])\n",
        "  arr_training_res[i,:,:,:] = arr_training_res[i,:,:,:] / amax_tmp"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Normalization of data into [0,1] interval...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WMbr-UNQZC4"
      },
      "source": [
        "Let us inspect one image from the array. Notice that the interval range is now a float number between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8k6cHerOvVz",
        "outputId": "299878ea-d8ee-4176-e70a-cb3525ec64a4"
      },
      "source": [
        "arr_training_res[1000-1,:,:,:]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.3875834 , 0.3875834 , 0.3875834 , ..., 0.38874385,\n",
              "         0.38903394, 0.38932404],\n",
              "        [0.38961416, 0.3901944 , 0.39048448, ..., 0.39657673,\n",
              "         0.39773718, 0.3988976 ],\n",
              "        [0.40034813, 0.40179867, 0.4032492 , ..., 0.41746446,\n",
              "         0.4192051 , 0.42094576],\n",
              "        ...,\n",
              "        [0.3948361 , 0.3948361 , 0.3948361 , ..., 0.39454597,\n",
              "         0.39454597, 0.39454597],\n",
              "        [0.3948361 , 0.3948361 , 0.3951262 , ..., 0.40382943,\n",
              "         0.40557006, 0.40760082],\n",
              "        [0.40934145, 0.4113722 , 0.41340294, ..., 0.42181608,\n",
              "         0.42210618, 0.42239627]],\n",
              "\n",
              "       [[0.3872933 , 0.3872933 , 0.3875834 , ..., 0.3913548 ,\n",
              "         0.3916449 , 0.39193502],\n",
              "        [0.39251524, 0.39280534, 0.39338556, ..., 0.39628664,\n",
              "         0.39657673, 0.39657673],\n",
              "        [0.39657673, 0.39657673, 0.39657673, ..., 0.3959965 ,\n",
              "         0.3959965 , 0.3959965 ],\n",
              "        ...,\n",
              "        [0.4029591 , 0.4029591 , 0.4029591 , ..., 0.4029591 ,\n",
              "         0.4029591 , 0.4029591 ],\n",
              "        [0.4029591 , 0.4029591 , 0.4029591 , ..., 0.4029591 ,\n",
              "         0.4029591 , 0.4032492 ],\n",
              "        [0.4032492 , 0.4032492 , 0.4035393 , ..., 0.4029591 ,\n",
              "         0.40266898, 0.4023789 ]],\n",
              "\n",
              "       [[0.40382943, 0.40382943, 0.40382943, ..., 0.4032492 ,\n",
              "         0.4032492 , 0.4032492 ],\n",
              "        [0.4032492 , 0.4032492 , 0.4035393 , ..., 0.4032492 ,\n",
              "         0.4032492 , 0.4029591 ],\n",
              "        [0.4029591 , 0.40266898, 0.40266898, ..., 0.4029591 ,\n",
              "         0.4029591 , 0.4029591 ],\n",
              "        ...,\n",
              "        [0.40527996, 0.40586016, 0.4067305 , ..., 0.41398317,\n",
              "         0.41485348, 0.41572383],\n",
              "        [0.41630402, 0.41688424, 0.41717437, ..., 0.41862488,\n",
              "         0.41862488, 0.41862488],\n",
              "        [0.41862488, 0.41862488, 0.41833478, ..., 0.41311285,\n",
              "         0.41224253, 0.4116623 ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.14070205, 0.14070205, 0.13606034, ..., 0.12880766,\n",
              "         0.12822744, 0.12706701],\n",
              "        [0.12561648, 0.12445605, 0.12329562, ..., 0.11981433,\n",
              "         0.11923411, 0.11807369],\n",
              "        [0.11749347, 0.11720336, 0.11633305, ..., 0.11691326,\n",
              "         0.11691326, 0.11662315],\n",
              "        ...,\n",
              "        [0.11430229, 0.11488251, 0.11604293, ..., 0.11575283,\n",
              "         0.11430229, 0.11546272],\n",
              "        [0.11807369, 0.12271541, 0.1302582 , ..., 0.29503918,\n",
              "         0.32695097, 0.35567158],\n",
              "        [0.3794604 , 0.3994778 , 0.41746446, ..., 0.5256745 ,\n",
              "         0.53495795, 0.537859  ]],\n",
              "\n",
              "       [[0.12097476, 0.12097476, 0.12039454, ..., 0.11720336,\n",
              "         0.11575283, 0.11517262],\n",
              "        [0.11575283, 0.11662315, 0.11691326, ..., 0.11604293,\n",
              "         0.11488251, 0.11430229],\n",
              "        [0.1145924 , 0.11546272, 0.11546272, ..., 0.12039454,\n",
              "         0.12416594, 0.13170873],\n",
              "        ...,\n",
              "        [0.48709023, 0.56367856, 0.62257034, ..., 0.5619379 ,\n",
              "         0.5822454 , 0.608065  ],\n",
              "        [0.63359445, 0.65564257, 0.6733391 , ..., 0.6005222 ,\n",
              "         0.5921091 , 0.58775747],\n",
              "        [0.58775747, 0.5894981 , 0.5915289 , ..., 0.58369595,\n",
              "         0.60255295, 0.6231506 ]],\n",
              "\n",
              "       [[0.12068465, 0.12068465, 0.11749347, ..., 0.11517262,\n",
              "         0.11488251, 0.1145924 ],\n",
              "        [0.1145924 , 0.11604293, 0.1183638 , ..., 0.41746446,\n",
              "         0.49927473, 0.5677401 ],\n",
              "        [0.61473745, 0.63881636, 0.64606905, ..., 0.62257034,\n",
              "         0.65129095, 0.6715985 ],\n",
              "        ...,\n",
              "        [0.6301131 , 0.589208  , 0.57122135, ..., 0.6425878 ,\n",
              "         0.6370757 , 0.63388455],\n",
              "        [0.64868003, 0.68523353, 0.7365825 , ..., 0.7856107 ,\n",
              "         0.76211196, 0.75776035],\n",
              "        [0.77429646, 0.8018567 , 0.8236147 , ..., 0.55149406,\n",
              "         0.60226285, 0.65361184]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0gubL7dRDfz"
      },
      "source": [
        "# **2. Create training and test subsets from input data**\n",
        "\n",
        "We'll randomly split the training data into a `training subset` and a `testing subset`. Scikit-learn offers a popular function called `train-test-split()`, which creates 4 subsets based on the input and output variables `X - arr_training_res` and `y - arr_gt`. The function takes the following kwargs.\n",
        "* `arrays`: input and output data arrays\n",
        "* `test_size`: a float number representing the proportion of the input dataset to include in the test subset\n",
        "* `random_state`: An integer assuring reproducibility of the random shuffling of the data\n",
        "\n",
        "We'll use 85% of the input data for training and 15% for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB7vhItcQw02",
        "outputId": "741f9de4-dce5-458c-8ddf-04fa1f51e1ee"
      },
      "source": [
        "test_size=0.15\n",
        "print('[AI4EO_MOOC]_log: Training (%0.2f %%) and validation (%0.2f %%) split..' % (\n",
        "      (1-test_size)*100,(test_size)*100))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        arr_training_res,\n",
        "        arr_gt,\n",
        "        test_size=test_size,\n",
        "        random_state=42)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Training (85.00 %) and validation (15.00 %) split..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjczIXyaTzuQ"
      },
      "source": [
        "# **3. Define the Convolutional Neural Network architecture**\n",
        "\n",
        "As our first step, we'll initiate a `sequential neural network` model with the Keras class `keras.Sequential()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4MBqhs0ULzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e62f42-8fc5-424b-d6a0-42b15c602861"
      },
      "source": [
        "_, num_classes = y_train.shape\n",
        "print('[AI4EO_MOOC]_log: Convolutional Neural Network architecture:')\n",
        "model = keras.Sequential()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: Convolutional Neural Network architecture:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQnyt479iNG8"
      },
      "source": [
        "The next step is to build up the architecture of the `Convolution Neural Network (CNN)`, with the function `model.add()`. A `CNN` composes of the following set of layers:\n",
        "\n",
        "* `Conv2D`: Convolutional layer with number of filters, e.g. 32 or 64, the shape of thje filter ((3,3), (5,5),...) and the application of padding\n",
        "* `Activation`: Activation layer, e.g. `relu`, `sigmoid`, ...\n",
        "* `Maxpooling2D`: Max Pooling layer with shape (2,2), (3,3), ...\n",
        "* `Dropout`: to reduce overfitting\n",
        "\n",
        "In the following code block, we build three blocks of layers:\n",
        "\n",
        "* **First block of layers**\n",
        "The first block of layers consist of two `Conv2D` layers with 32 neurons and we add non-linear properties by adding an `Activation` layer in between. We then define a `MaxPooling2D` layer, which downsamples the input by taking the maximum value of a given window size. The block of layers finishes with `Dropout` layer, which randomly skips 25% of the interconnections.\n",
        "\n",
        "* **Second block of layers**\n",
        "The second block of layers consists of two `Conv2D` layers, but with 64 neurons and we add non-linear properties by adding an `Activation` layer in between. We then define a `MaxPooling2D` layer, which downsamples the input by taking the maximum value of a given window size. The block of layers finishes with a  `Dropout` layer, which randomly skips 25% of the interconnections.\n",
        "\n",
        "* **Third block of layers**\n",
        "The third block consists of two `Dense` layers, which are fully-connected layers. In between, we again add non-linear properties by adding an `Activation` layer. The number of neurons of the final 'Dense` layer has to be the same as the number of land use classes, in this case 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNZhkwRLmPI8"
      },
      "source": [
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGAFthPApDpK"
      },
      "source": [
        "After the model architecture has been defined you can compile(configure) the model with `model.compile()` and define the following hyperparameters:\n",
        "\n",
        "* `loss='categorical_crossentropy'`- Categorical crossentropy is one of many loss options and calculates the crossentropy loss between the labels and the predictions\n",
        "* `optimizer=RMSprop(lr=0.0001, decay=1e-6)`- Optimizers are algorithms the network learns from\n",
        "* `metrics=['accuracy']`- is used to evaluate how the model is performing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLS4oUxNn0Yy",
        "outputId": "352223b1-398c-4ea5-b386-ed35791ddeef"
      },
      "source": [
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSWECAheqqgv"
      },
      "source": [
        "The function `model.summary()` provides you a tabular summary of the `CNN architecture`, which is helpful for seeing what the output shape of the model looks like after each operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAdMW9brzno6",
        "outputId": "f8a2fcc5-8daa-4734-cc35-8f3f9630c390"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 32)        3776      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 62, 62, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 62, 62, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 32)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 31, 31, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 29, 29, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               6423040   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,496,618\n",
            "Trainable params: 6,496,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUeKZSuPHbBd"
      },
      "source": [
        "##**4. Fitting (training) of the convolutional neural network**\n",
        "\n",
        "The next step in the training process is the actual training (fitting) of the model.\n",
        "\n",
        "We'll set a folder path to which the model with the best validation accuracy is saved to. The pre-trained model is saved in the folder `02_pretrained_model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sjmNyISLzukg",
        "outputId": "e15a2ab2-d58b-458e-8297-3b4dfa23bca4"
      },
      "source": [
        "save_dir = 'drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/'\n",
        "model_name = 'keras_sentinel2_classification_trained_model_e50.json'\n",
        "\n",
        "filepath_tmp = save_dir+model_name\n",
        "filepath_tmp"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA5853KGJjPk"
      },
      "source": [
        "`Callbacks` are utilitiesthat are called at certain points during model training. They can support us in better understanding the performance of our model during training. One useful callback is *ModelCheckpoint*, which allows us to save the Keras model after training. With class `ModelCheckpoint` we can define the type of information we would like to save.\n",
        "\n",
        "The following code saves only the model with the best `validation accuracy`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFMqge5mJfX8"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    filepath_tmp,\n",
        "    'val_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvMTyXSLOjj7"
      },
      "source": [
        "The final step is to train (fit) the Keras model. We can use `model.fit()` to fit the model based on the training dataset. The resulting object is a `history` object and a common practise is to call the output of the training process `history`.\n",
        "\n",
        "The function `model.fit()` requires us to to specify the following parameters:\n",
        "* `input (X)` and `output (y)` data: here we specify the input and output data of our model\n",
        "* `validation_data`: here we enter the test data subsets X_test and y_test and our model outputs are validated against these validation data for each epoch (training cycle)\n",
        "* `epochs`: number of training cycles\n",
        "* `batch_size`: defines the size of the training data subsets (eg. 32 samples) after which the weights of the network are updated\n",
        "* `callbacks`: define the callbacks we would like to make use of during the training process\n",
        "* `verbose`: specify how the progress of the training shall be shown - option 0,1,2 - option 1 for e.g. shows us a progress bar for each epoch                          "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmzqhUCuLTka",
        "outputId": "4217e27d-6a8e-4d3b-9a5d-7df6ff9f7fee"
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks=callbacks_list,\n",
        "                    verbose = 1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.4699 - accuracy: 0.4622\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.63600, saving model to drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json\n",
            "INFO:tensorflow:Assets written to: drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json/assets\n",
            "266/266 [==============================] - 188s 702ms/step - loss: 1.4699 - accuracy: 0.4622 - val_loss: 1.0352 - val_accuracy: 0.6360\n",
            "Epoch 2/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 1.0139 - accuracy: 0.6349\n",
            "Epoch 00002: val_accuracy improved from 0.63600 to 0.74400, saving model to drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json\n",
            "INFO:tensorflow:Assets written to: drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json/assets\n",
            "266/266 [==============================] - 187s 705ms/step - loss: 1.0139 - accuracy: 0.6349 - val_loss: 0.8301 - val_accuracy: 0.7440\n",
            "Epoch 3/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 0.8701 - accuracy: 0.6845\n",
            "Epoch 00003: val_accuracy did not improve from 0.74400\n",
            "266/266 [==============================] - 186s 698ms/step - loss: 0.8701 - accuracy: 0.6845 - val_loss: 0.8549 - val_accuracy: 0.6647\n",
            "Epoch 4/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 0.7740 - accuracy: 0.7226\n",
            "Epoch 00004: val_accuracy did not improve from 0.74400\n",
            "266/266 [==============================] - 185s 697ms/step - loss: 0.7740 - accuracy: 0.7226 - val_loss: 0.7036 - val_accuracy: 0.7293\n",
            "Epoch 5/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.7579\n",
            "Epoch 00005: val_accuracy improved from 0.74400 to 0.77333, saving model to drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json\n",
            "INFO:tensorflow:Assets written to: drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json/assets\n",
            "266/266 [==============================] - 186s 701ms/step - loss: 0.6953 - accuracy: 0.7579 - val_loss: 0.6233 - val_accuracy: 0.7733\n",
            "Epoch 6/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 0.6435 - accuracy: 0.7732\n",
            "Epoch 00006: val_accuracy improved from 0.77333 to 0.81333, saving model to drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json\n",
            "INFO:tensorflow:Assets written to: drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json/assets\n",
            "266/266 [==============================] - 186s 701ms/step - loss: 0.6435 - accuracy: 0.7732 - val_loss: 0.5389 - val_accuracy: 0.8133\n",
            "Epoch 7/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.7885\n",
            "Epoch 00007: val_accuracy improved from 0.81333 to 0.83600, saving model to drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json\n",
            "INFO:tensorflow:Assets written to: drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json/assets\n",
            "266/266 [==============================] - 187s 702ms/step - loss: 0.6067 - accuracy: 0.7885 - val_loss: 0.5084 - val_accuracy: 0.8360\n",
            "Epoch 8/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 0.5543 - accuracy: 0.7981\n",
            "Epoch 00008: val_accuracy did not improve from 0.83600\n",
            "266/266 [==============================] - 184s 693ms/step - loss: 0.5543 - accuracy: 0.7981 - val_loss: 0.4957 - val_accuracy: 0.8287\n",
            "Epoch 9/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 0.5268 - accuracy: 0.8147\n",
            "Epoch 00009: val_accuracy did not improve from 0.83600\n",
            "266/266 [==============================] - 184s 691ms/step - loss: 0.5268 - accuracy: 0.8147 - val_loss: 0.5287 - val_accuracy: 0.8187\n",
            "Epoch 10/10\n",
            "266/266 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.8212\n",
            "Epoch 00010: val_accuracy improved from 0.83600 to 0.84600, saving model to drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json\n",
            "INFO:tensorflow:Assets written to: drive/MyDrive/Land Classification/S2_Tile_based_classification/02_pretrained_model/keras_sentinel2_classification_trained_model_e50.json/assets\n",
            "266/266 [==============================] - 186s 698ms/step - loss: 0.5032 - accuracy: 0.8212 - val_loss: 0.4487 - val_accuracy: 0.8460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhM2OOUZDoaN"
      },
      "source": [
        "##**5. Evaluate the performance of the CNN model with a confusion matrix\n",
        "\n",
        "The final step is to evaluate the performance of our model and the model's ability to classify landcover / land use with the help of the test data. With the function `model.predict()`, we can classify the test input data `(X_test)`. The result `y_pred` is an array with the dimension `(1500, 10)`. For each input image of the test data, the prediction provides a vector which holds for each class the probability of the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs3umb9WRiwr",
        "outputId": "5c595abf-e34c-48c0-fc05-c4b46ce87e68"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqbGlMgbE-FO"
      },
      "source": [
        "The final classification result is the class with the highest probability. The objective is to have a vector with the same length as the number of test images, which provides for each image the final predicted class. To achieve this, we have to loop over the predicted `(y_pred)` and test `(y_test)` output arrays and retrieve the index of the argument with the maximum value. We can retrieve the index of the argument with the maximum value with numpy's function `np.argmax()`.\n",
        "\n",
        "The result are two one dimensional arrays, `y_pred_amax` and `y_test_amax`, providing the index of the land cover class for each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2pHYhdNE5aA",
        "outputId": "93cc9d04-2755-48cb-d8cc-872bd0f022c0"
      },
      "source": [
        "y_pred_amax=np.zeros((len(y_pred)))\n",
        "y_test_amax=np.zeros((len(y_pred)))\n",
        "\n",
        "for i in range(0,len(y_pred)):\n",
        "    y_pred_amax[i]=np.argmax(y_pred[i,:])\n",
        "    y_test_amax[i]=np.argmax(y_test[i,:])\n",
        "\n",
        "y_test_amax, y_pred_amax"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([6., 4., 1., ..., 6., 6., 3.]), array([6., 4., 1., ..., 6., 6., 3.]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoBSfrY_Ii3F"
      },
      "source": [
        "###**Create a confusion matrix**\n",
        "\n",
        "Classification accuracy alone can often be misleading, esp. if you have an unequal number of observations in each class or if you have more than two classes in your dataset. A confusion matrix can give you a better idea of what your model is getting right and what type of errors it is making. A `confusion matrix` is also known as an error matrix and is a common technique for summerizing the performance of a classification algorithm.\n",
        "\n",
        "The metrics class of the scikit-learn package offers the function `confusion_matrix`, which computes the confusion matrix between the actual (`y_test_amax`) and predicted class (`y_pred_amax`). The result is a matrix which ummerizes the number of correct and incorrect predictions with count values broken down by each class. The rows indicate the actual class and the columns indicate the predicted class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4g0E5fWHZ75",
        "outputId": "acedb5c3-c252-412a-a265-7cf2299c3b99"
      },
      "source": [
        "matrix = metrics.confusion_matrix(y_test_amax, y_pred_amax)\n",
        "matrix"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[148,   1,   1,   0,   0,  10,   0,   1,   0,   0],\n",
              "       [  2, 149,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0, 116,   0,   5,   8,   0,   5,   3,   3],\n",
              "       [  0,   0,   0, 144,   1,   0,   0,   4,   0,   0],\n",
              "       [  7,   0,   0,   4, 105,   6,   1,  16,  14,   3],\n",
              "       [  4,   0,   6,   0,   7, 100,   5,   1,   6,  10],\n",
              "       [  0,   0,   0,   0,   2,   2, 139,   0,   0,  10],\n",
              "       [  1,   0,   3,  17,   5,   6,   0, 117,   5,   1],\n",
              "       [  1,   0,   4,   0,   5,  19,   0,   2, 131,   5],\n",
              "       [  0,   0,   0,   0,   0,   2,   5,   0,   2, 120]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7apgYNApLbM8"
      },
      "source": [
        "Let's convert the matrix into a `pandas.dataframe` and add class labelks to the rows and columns.  This helps better interpret the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Rvnm0OceK2MD",
        "outputId": "a0d12fdb-88d5-479d-ae97-d5430a08590a"
      },
      "source": [
        "label_str=[\n",
        "    'Annual Crop',\n",
        "    'Forest',\n",
        "    'HerbaceousVegetation',\n",
        "    'Highway',\n",
        "    'Industrial',\n",
        "    'Pasture',\n",
        "    'PermanentCrop',\n",
        "    'Residential',\n",
        "    'River',\n",
        "    'SeaLake' ]\n",
        "\n",
        "con_mat_df = pd.DataFrame(matrix,\n",
        "                                index = label_str,\n",
        "                                columns = label_str)\n",
        "con_mat_df"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Annual Crop</th>\n",
              "      <th>Forest</th>\n",
              "      <th>HerbaceousVegetation</th>\n",
              "      <th>Highway</th>\n",
              "      <th>Industrial</th>\n",
              "      <th>Pasture</th>\n",
              "      <th>PermanentCrop</th>\n",
              "      <th>Residential</th>\n",
              "      <th>River</th>\n",
              "      <th>SeaLake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Annual Crop</th>\n",
              "      <td>148</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Forest</th>\n",
              "      <td>2</td>\n",
              "      <td>149</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HerbaceousVegetation</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Highway</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>144</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Industrial</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>105</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pasture</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>100</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PermanentCrop</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Residential</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>117</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>River</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>131</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SeaLake</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Annual Crop  Forest  ...  River  SeaLake\n",
              "Annual Crop                   148       1  ...      0        0\n",
              "Forest                          2     149  ...      0        0\n",
              "HerbaceousVegetation            0       0  ...      3        3\n",
              "Highway                         0       0  ...      0        0\n",
              "Industrial                      7       0  ...     14        3\n",
              "Pasture                         4       0  ...      6       10\n",
              "PermanentCrop                   0       0  ...      0       10\n",
              "Residential                     1       0  ...      5        1\n",
              "River                           1       0  ...    131        5\n",
              "SeaLake                         0       0  ...      2      120\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YEcVx4LM-b-"
      },
      "source": [
        "Now we can use the `heatmap()` function of the seaborn library to visualize the confusion matrix. This gives us a more visual picture of the classification of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "vYyR4BJ3Mkdj",
        "outputId": "c86b51a8-39de-43b0-f035-13dce6c2cc4c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(con_mat_df,\n",
        "            annot=True,\n",
        "            fmt='d',\n",
        "            cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqxSmy9wN_Y1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}