{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tile-based classification using Sentinel-2 and EuroSAT data-Training.ipynb",
      "provenance": [],
      "mount_file_id": "1Nb6axbd2makj-lAkYy_81CqLwf8aKOQ9",
      "authorship_tag": "ABX9TyMjSnkyxJKHNemauQTyTVna",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMoronto/ml-unstructured-data-projects/blob/master/Tile_based_classification_using_Sentinel_2_and_EuroSAT_data_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeFaI7puszgm"
      },
      "source": [
        "##**Intro**\n",
        "\n",
        "This workflow explores the process of training a `Convolutional Neural Network (CNN)` with Keras based on the benchmark dataset EuroSAT. This noote book contains notes I've taken as I work through the example workflow presented in the AI for Earth monitoring MOOC on Futurelearn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkSeuefswyfX"
      },
      "source": [
        "##**Machine-Learning Algorithm**\n",
        "\n",
        "This example develops a `Sequential Convolutional Neural Network (CNN)` with TF Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyS5FFHUxcN_"
      },
      "source": [
        "##**Data**\n",
        "The model is trained on the EuroSAT benchmark dataset which is based on Sentinel-2 satellite images and consists of 27,000 labeled and geo-referenced images.The dataset provides information on the following ten land cover/land use cases:\n",
        "* `Annual Crop`\n",
        "* `Forest`\n",
        "* `Herbaceous Vegetation`\n",
        "* `Highway`\n",
        "* Industrial`\n",
        "* `Pasture`\n",
        "* `Permanent Crop`\n",
        "* `Residential`\n",
        "* `River`\n",
        "* `Sea Lake`\n",
        "\n",
        "The benchmark dataset can be used to detect `land cover / land use changes`. The geo-referenced datasset EuroSAT is publicly accessible here: https://github.com/phelber/eurosat\n",
        "\n",
        "## Notebook Outline\n",
        "* 1 - Load the EuroSAT benchmark dataset as input data\n",
        "* 2 - Create training and test subsets from input data\n",
        "* 3 - Define the Convolutional Neural Network architecture\n",
        "* 4 - Fit (train) the convolutional neural network (CNN)\n",
        "* 5 - Evaluate the performance of the CNN model with a confusion matrix\n",
        "\n",
        "\n",
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsppuKATLSor"
      },
      "source": [
        "## Begin S3FS Import Snippet ##\n",
        "import os, sys\n",
        "s3_home = os.getcwd()\n",
        "try: sys.path.remove(s3_home) # Remove the S3 from the $path\n",
        "except Exception: pass\n",
        "\n",
        "# current_dir = os.getcwd()\n",
        "\n",
        "# os.chdir('/home/jovyan') # Temporarily move to another directory\n",
        "\n",
        "# Begin imports #\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from osgeo import gdal_array\n",
        "from matplotlib import pyplot as pyplot\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import zipfile\n",
        "# end imports #\n",
        "\n",
        "os.chdir(current_dir) # go back to your previous dir\n",
        "\n",
        "sys.path.append(s3_home) # restore the s3 root in the $path\n",
        "\n",
        "## end s3fs import snippet ##\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttI_pu8vzd8_"
      },
      "source": [
        "# !unzip \"drive/MyDrive/Land Classification/S2_Tile_based_classification.zip\" -d \"drive/MyDrive/Land Classification/\""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-DF0lwEWyWk"
      },
      "source": [
        "Define helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3mvsK6CKOO-"
      },
      "source": [
        "from_folder_to_stack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwNtHfldXIaf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "'''\n",
        "function name:\n",
        "  from_folder_to_stack\n",
        "description:\n",
        "  This function transforms the .SAFE file into three different arrays (10m, 20m and 60m).\n",
        "Input:\n",
        "  safe_path: the path of the .SAFE file;\n",
        "  data_bands_20m: if True, the fumnction computes stack using Sentinel2 band with 20m of pixel resolution (default=True);\n",
        "  data_bands_60m: if True, the function computes stack using Sentinel2 band with 60m of pixel resolution (default=True);\n",
        "Output:\n",
        "  stack_10m: stack with the following S2L1C bands (B02, B03, B04, B08)\n",
        "  stack_20m: stack with the following S2L1C bands (B05, B06, B07, B11, B12, B8A)\n",
        "  stack_60m: stack with the following S2L1C bands (B01, mB09, B10)\n",
        "'''\n",
        "def from_folder_to_stack(\n",
        "    safe_path,\n",
        "    data_bands_20m=True,\n",
        "    data_bands_60m=True,\n",
        "    ):\n",
        "\n",
        "  level_folder_name_list = glob.glob(safe_path + 'GRANULE/*')\n",
        "  level_folder_name = level_folder_name_list[0]\n",
        "\n",
        "  if level_folder_name.find(\"L2A\") < 0:\n",
        "    safe_path = [level_folder_name + '/IMG_DATA/']\n",
        "  else:\n",
        "    safe_path_10m = level_folder_name + '/IMG_DATA/R10m/'\n",
        "    safe_path = [safe_path_10m]\n",
        "\n",
        "  text_files = []\n",
        "\n",
        "  for i in range(0, len(safe_path)):\n",
        "      print(\"[AI4EO_MOOC]_log: Loading .jp2 images in %s\" % (safe_path[i]))\n",
        "      text_files_tmp = [f for f in os.listdir(safe_path[i]) if f.endswith('.jp2')]\n",
        "      text_files.append(text_files_tmp)\n",
        "\n",
        "  lst_stack_60m=[]\n",
        "  lst_code_60m=[]\n",
        "  lst_stack_20m=[]\n",
        "  lst_code_20m=[]\n",
        "  lst_stack_10m=[]\n",
        "  lst_code_10m=[]\n",
        "  for i in range(0, len(safe_path)):\n",
        "\n",
        "    print(\"[AI4EO_MOOC]_log: Reading .jp2 files in %s\" % (safe_path[i]))\n",
        "    for name in range(0, len(text_files[i])):\n",
        "      text_files_tmp = text_files[i]\n",
        "      if data_bands_60m == True:\n",
        "        cond_60m = ( (text_files_tmp[name].find(\"B01\") > 0) or (text_files_tmp[name].find(\"B09\") > 0)\n",
        "                    or (text_files_tmp[name].find(\"B10\") > 0))\n",
        "        if cond_60m:\n",
        "            print(\"[AI4EO_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "            lst_stack_60m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "            lst_code_60m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "      if data_bands_20m == True:\n",
        "          cond_20m = (text_files_tmp[name].find(\"B05\") > 0) or (text_files_tmp[name].find(\"B06\") > 0) or (\n",
        "                      text_files_tmp[name].find(\"B07\") > 0) or (text_files_tmp[name].find(\"B11\") > 0) or (\n",
        "                                  text_files_tmp[name].find(\"B12\") > 0) or (text_files_tmp[name].find(\"B8A\") > 0)\n",
        "          cond_60m_L2 = (text_files_tmp[name].find(\"B05_60m\") < 0) and (text_files_tmp[name].find(\"B06_60m\") < 0) and (\n",
        "                      text_files_tmp[name].find(\"B07_60m\") < 0) and (text_files_tmp[name].find(\"B11_60m\") < 0) and (\n",
        "                                  text_files_tmp[name].find(\"B12_60m\") < 0) and (text_files_tmp[name].find(\"B8A_60m\") < 0)\n",
        "          cond_20m_tot = cond_20m and cond_60m_L2\n",
        "          if cond_20m_tot:\n",
        "              print(\"[AI4E_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "              lst_stack_20m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "              lst_code_20m.append(text_files_tmp[name][24:26])\n",
        "      else:\n",
        "        stack_20m = 0\n",
        "\n",
        "      cond_10m = (text_files_tmp[name].find(\"B02\") > 0) or (text_files_tmp[name].find(\"B03\") > 0) or (\n",
        "                  text_files_tmp[name].find(\"B04\") > 0) or (text_files_tmp[name].find(\"B08\") > 0)\n",
        "      cond_20m_L2 = (text_files_tmp[name].find(\"B02_20m\") < 0) and (text_files_tmp[name].find(\"B03_20m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_20m\") < 0) and (text_files_tmp[name].find(\"B08_20m\") < 0)\n",
        "      cond_60m_L2 = (text_files_tmp[name].find(\"B02_60m\") < 0) and (text_files_tmp[name].find(\"B03_60m\") < 0) and (\n",
        "                  text_files_tmp[name].find(\"B04_60m\") < 0) and (text_files_tmp[name].find(\"B08_60m\") < 0)\n",
        "      cond_10m_tot = cond_10m and cond_20m_L2 and cond_60m_L2\n",
        "\n",
        "      if cond_10m_tot:\n",
        "          print(\"[AI4E)_MOOC]_log: Using .jp2 image: %s\" % text_files_tmp[name])\n",
        "          lst_stack_10m.append(gdal_array.LoadFile(safe_path[i] + text_files_tmp[name]))\n",
        "          lst_code_10m.append(text_files_tmp[name][24:26])\n",
        "\n",
        "\n",
        "  stack_10m=np.asarray(lst_stack_10m)\n",
        "  sorted_list_10m = ['02', '03', '04', '08']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 10m...')\n",
        "  stack_10m_final_sorted = stack_sort(stack_10m, lst_code_10m, sorted_list_10m)\n",
        "\n",
        "  stack_20m=np.asarray(lst_stack_20m)\n",
        "  sorted_list_20m = ['05', '06', '07', '11', '12', '8A']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 20m...')\n",
        "  stack_20m_final_sorted = stack_sort(stack_20m, lst_code_20m, sorted_list_20m)\n",
        "              \n",
        "  stack_60m=np.asarray(lst_stack_60m)\n",
        "  sorted_list_60m = ['01', '09', '10']\n",
        "  print('[AI4EO_MOOC]_log: Sorting stack 60m...')\n",
        "  stack_60m_final_sorted = stack_sort(stack_60m, lst_code_60m, sorted_list_60m)\n",
        "\n",
        "  return stack_10m_final_sorted, stack_20m_final_sorted, stack_60m_final_sorted"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwSv2ExkGK9e"
      },
      "source": [
        "stack_sort"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW6E0LvU_wB0"
      },
      "source": [
        "def stack_sort(stack_in, lst_code, sorted_list):\n",
        "  b, r, c = stack_in.shape\n",
        "  stack_sorted = np.zeros((r,c,b), dtype=np.unit16)\n",
        "\n",
        "  len_list_bands = len(lst_code)\n",
        "\n",
        "  c = np.zeros((len_list_bands), dtype=np.unit8)\n",
        "  count = 0\n",
        "  count_sort = 0\n",
        "  while count_sort != len_list_bands:\n",
        "    if lst_code[count] == sorted_list[count_sort]:\n",
        "      c[count_sort] = count\n",
        "      count_sort = count_sort + 1\n",
        "      count = 0\n",
        "    else:\n",
        "      count = count + 1\n",
        "    print('[AI4EO_MOOC]_log: sorted list:', sorted_list)\n",
        "    print('[AI4EO_MOOC]_log: bands:', c)\n",
        "    for i in range(0, len_list_bands):\n",
        "        stack_sorted[:,:,i]=stack_in[c[i],:,:]\n",
        "    \n",
        "    return stack_sorted"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYkZZV_IrQs"
      },
      "source": [
        "resample_3d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS-jKoKI8uK"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0Kp7sWIwPk"
      },
      "source": [
        "sentinel2_format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3mAuYCJAO-"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_P1HyB9I3Y8"
      },
      "source": [
        "sliding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfdgOtpfI-TY"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncaoujg8H-7h"
      },
      "source": [
        "# **1. Load the EuroSAT benchmark dataset as input data**\n",
        "The `EuroSAT benchmark dataset` is `drive/MyDrive/Land Classificatiion/S2_Tile_based_classification/01_Input_data/S2_tile_4_training/`. This folder contains a folder for each of the ten land cover classes. The first step involves loading all the EuroSAT images from all the folders as a `numpy` array. You can use the function `.LoadFile` from the GDAL Python bindings module `gdal_array` to read a raster image (e.g. in `.tif` format) into a `numpy.array`.\n",
        "\n",
        "The result is `lst_arr_training`, a list of 10,000 arrays and each array has the dimension `[13, 64, 64]`. For each of the images we want to create a `numpy.array` with ten entries indicating in binary form (0 or 1) the class the image belongs to. The resulting list is called `lst_gt_training` and has the same length as the list of training images.\n",
        "\n",
        "**NOTE**: for training purposes, the example only makes use of a subset of 10,000 images of the EuroSAT benchmark dataset(27,000 images).\n",
        "\n",
        "\n",
        "Define the folder where the EuroSAT training images are located."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlvPBWKQhQD"
      },
      "source": [
        "# MAIN_PATH = 'drive/MyDrive/Land Classification/S2_Tile_based_classification/'\n",
        "DATA_PATH = 'drive/MyDrive/Land Classification/S2_Tile_based_classification/01_Input_data/S2_tile_4_training/'"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5F7sVtqRBWN"
      },
      "source": [
        "Loop over the training data folders and build up two lists:\n",
        "\n",
        "* `lst_arr_training` - List of training arrays\n",
        "* `lst_gt_training` _ List of arrays indicating to which class each image belongs to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPzhHYgYRjp0",
        "outputId": "ea52f003-6461-40ea-a3d8-396d82177746"
      },
      "source": [
        "import glob\n",
        "len_data_for_training_tmp = 1000\n",
        "# folder_for_training = glob.glob(MAIN_PATH+DATA_PATH+'*/')\n",
        "folder_for_training = glob.glob(DATA_PATH+'*/')\n",
        "\n",
        "print('[AI4EO_MOOC]_log: There are %d folders' % (len(folder_for_training)))\n",
        "\n",
        "lst_arr_training=[]\n",
        "lst_gt_training = []\n",
        "for i in range(0,len(folder_for_training)):\n",
        "  data_for_training_tmp=glob.glob(folder_for_training[i]+'*.tif')\n",
        "\n",
        "  print('[AI4EO_MOOC]_log: There are %d images for %s class' % (\n",
        "      \n",
        "      len_data_for_training_tmp, folder_for_training[i][40:-1])\n",
        "      )\n",
        "  \n",
        "  for j in range(0, len_data_for_training_tmp):\n",
        "      arr_tmp = gdal_array.LoadFile(data_for_training_tmp[j])\n",
        "      lst_arr_training.append(arr_tmp)\n",
        "      tmp_gt = np.zeros(10)\n",
        "      tmp_gt[i]=1\n",
        "      lst_gt_training.append(tmp_gt)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AI4EO_MOOC]_log: There are 10 folders\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/AnnualCrop class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Forest class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/HerbaceousVegetation class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Highway class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Industrial class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Pasture class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/PermanentCrop class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/Residential class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/River class\n",
            "[AI4EO_MOOC]_log: There are 1000 images for e_based_classification/01_Input_data/S2_tile_4_training/SeaLake class\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTGiHQLMUg-q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}